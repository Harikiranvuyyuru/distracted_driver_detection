1: input_1
2: lambda_1
3: conv2d_1
4: batch_normalization_1
5: activation_1
6: conv2d_2
7: batch_normalization_2
8: activation_2
9: conv2d_3
10: batch_normalization_3
11: activation_3
12: max_pooling2d_1
13: conv2d_4
14: batch_normalization_4
15: activation_4
16: conv2d_5
17: batch_normalization_5
18: activation_5
19: max_pooling2d_2
20: conv2d_9
21: batch_normalization_9
22: activation_9
23: conv2d_7
24: conv2d_10
25: batch_normalization_7
26: batch_normalization_10
27: activation_7
28: activation_10
29: average_pooling2d_1
30: conv2d_6
31: conv2d_8
32: conv2d_11
33: conv2d_12
34: batch_normalization_6
35: batch_normalization_8
36: batch_normalization_11
37: batch_normalization_12
38: activation_6
39: activation_8
40: activation_11
41: activation_12
42: mixed0
43: conv2d_16
44: batch_normalization_16
45: activation_16
46: conv2d_14
47: conv2d_17
48: batch_normalization_14
49: batch_normalization_17
50: activation_14
51: activation_17
52: average_pooling2d_2
53: conv2d_13
54: conv2d_15
55: conv2d_18
56: conv2d_19
57: batch_normalization_13
58: batch_normalization_15
59: batch_normalization_18
60: batch_normalization_19
61: activation_13
62: activation_15
63: activation_18
64: activation_19
65: mixed1
66: conv2d_23
67: batch_normalization_23
68: activation_23
69: conv2d_21
70: conv2d_24
71: batch_normalization_21
72: batch_normalization_24
73: activation_21
74: activation_24
75: average_pooling2d_3
76: conv2d_20
77: conv2d_22
78: conv2d_25
79: conv2d_26
80: batch_normalization_20
81: batch_normalization_22
82: batch_normalization_25
83: batch_normalization_26
84: activation_20
85: activation_22
86: activation_25
87: activation_26
88: mixed2
89: conv2d_28
90: batch_normalization_28
91: activation_28
92: conv2d_29
93: batch_normalization_29
94: activation_29
95: conv2d_27
96: conv2d_30
97: batch_normalization_27
98: batch_normalization_30
99: activation_27
100: activation_30
101: max_pooling2d_3
102: mixed3
103: conv2d_35
104: batch_normalization_35
105: activation_35
106: conv2d_36
107: batch_normalization_36
108: activation_36
109: conv2d_32
110: conv2d_37
111: batch_normalization_32
112: batch_normalization_37
113: activation_32
114: activation_37
115: conv2d_33
116: conv2d_38
117: batch_normalization_33
118: batch_normalization_38
119: activation_33
120: activation_38
121: average_pooling2d_4
122: conv2d_31
123: conv2d_34
124: conv2d_39
125: conv2d_40
126: batch_normalization_31
127: batch_normalization_34
128: batch_normalization_39
129: batch_normalization_40
130: activation_31
131: activation_34
132: activation_39
133: activation_40
134: mixed4
135: conv2d_45
136: batch_normalization_45
137: activation_45
138: conv2d_46
139: batch_normalization_46
140: activation_46
141: conv2d_42
142: conv2d_47
143: batch_normalization_42
144: batch_normalization_47
145: activation_42
146: activation_47
147: conv2d_43
148: conv2d_48
149: batch_normalization_43
150: batch_normalization_48
151: activation_43
152: activation_48
153: average_pooling2d_5
154: conv2d_41
155: conv2d_44
156: conv2d_49
157: conv2d_50
158: batch_normalization_41
159: batch_normalization_44
160: batch_normalization_49
161: batch_normalization_50
162: activation_41
163: activation_44
164: activation_49
165: activation_50
166: mixed5
167: conv2d_55
168: batch_normalization_55
169: activation_55
170: conv2d_56
171: batch_normalization_56
172: activation_56
173: conv2d_52
174: conv2d_57
175: batch_normalization_52
176: batch_normalization_57
177: activation_52
178: activation_57
179: conv2d_53
180: conv2d_58
181: batch_normalization_53
182: batch_normalization_58
183: activation_53
184: activation_58
185: average_pooling2d_6
186: conv2d_51
187: conv2d_54
188: conv2d_59
189: conv2d_60
190: batch_normalization_51
191: batch_normalization_54
192: batch_normalization_59
193: batch_normalization_60
194: activation_51
195: activation_54
196: activation_59
197: activation_60
198: mixed6
199: conv2d_65
200: batch_normalization_65
201: activation_65
202: conv2d_66
203: batch_normalization_66
204: activation_66
205: conv2d_62
206: conv2d_67
207: batch_normalization_62
208: batch_normalization_67
209: activation_62
210: activation_67
211: conv2d_63
212: conv2d_68
213: batch_normalization_63
214: batch_normalization_68
215: activation_63
216: activation_68
217: average_pooling2d_7
218: conv2d_61
219: conv2d_64
220: conv2d_69
221: conv2d_70
222: batch_normalization_61
223: batch_normalization_64
224: batch_normalization_69
225: batch_normalization_70
226: activation_61
227: activation_64
228: activation_69
229: activation_70
230: mixed7
231: conv2d_73
232: batch_normalization_73
233: activation_73
234: conv2d_74
235: batch_normalization_74
236: activation_74
237: conv2d_71
238: conv2d_75
239: batch_normalization_71
240: batch_normalization_75
241: activation_71
242: activation_75
243: conv2d_72
244: conv2d_76
245: batch_normalization_72
246: batch_normalization_76
247: activation_72
248: activation_76
249: max_pooling2d_4
250: mixed8
251: conv2d_81
252: batch_normalization_81
253: activation_81
254: conv2d_78
255: conv2d_82
256: batch_normalization_78
257: batch_normalization_82
258: activation_78
259: activation_82
260: conv2d_79
261: conv2d_80
262: conv2d_83
263: conv2d_84
264: average_pooling2d_8
265: conv2d_77
266: batch_normalization_79
267: batch_normalization_80
268: batch_normalization_83
269: batch_normalization_84
270: conv2d_85
271: batch_normalization_77
272: activation_79
273: activation_80
274: activation_83
275: activation_84
276: batch_normalization_85
277: activation_77
278: mixed9_0
279: concatenate_1
280: activation_85
281: mixed9
282: conv2d_90
283: batch_normalization_90
284: activation_90
285: conv2d_87
286: conv2d_91
287: batch_normalization_87
288: batch_normalization_91
289: activation_87
290: activation_91
291: conv2d_88
292: conv2d_89
293: conv2d_92
294: conv2d_93
295: average_pooling2d_9
296: conv2d_86
297: batch_normalization_88
298: batch_normalization_89
299: batch_normalization_92
300: batch_normalization_93
301: conv2d_94
302: batch_normalization_86
303: activation_88
304: activation_89
305: activation_92
306: activation_93
307: batch_normalization_94
308: activation_86
309: mixed9_1
310: concatenate_2
311: activation_94
312: mixed10
313: global_average_pooling2d_1
314: dropout_1
315: dense_1
Epoch 1/10
257/257 [==============================] - 690s 3s/step - loss: 0.2756 - acc: 0.9236 - val_loss: 0.3693 - val_acc: 0.9107

Epoch 00001: val_loss improved from inf to 0.36926, saving model to model/inceptionv3-finetune.hdf5
Epoch 2/10
257/257 [==============================] - 501s 2s/step - loss: 0.0078 - acc: 0.9985 - val_loss: 0.2918 - val_acc: 0.9204

Epoch 00002: val_loss improved from 0.36926 to 0.29178, saving model to model/inceptionv3-finetune.hdf5
Epoch 3/10
257/257 [==============================] - 506s 2s/step - loss: 0.0046 - acc: 0.9993 - val_loss: 0.3883 - val_acc: 0.9039

Epoch 00003: val_loss did not improve from 0.29178
Epoch 4/10
257/257 [==============================] - 506s 2s/step - loss: 8.8076e-04 - acc: 1.0000 - val_loss: 0.3104 - val_acc: 0.9320

Epoch 00004: val_loss did not improve from 0.29178
Epoch 5/10
257/257 [==============================] - 502s 2s/step - loss: 5.4804e-04 - acc: 0.9999 - val_loss: 0.2377 - val_acc: 0.9488

Epoch 00005: val_loss improved from 0.29178 to 0.23771, saving model to model/inceptionv3-finetune.hdf5
Epoch 6/10
257/257 [==============================] - 507s 2s/step - loss: 0.0043 - acc: 0.9993 - val_loss: 0.3037 - val_acc: 0.9388

Epoch 00006: val_loss did not improve from 0.23771
Epoch 7/10
257/257 [==============================] - 506s 2s/step - loss: 0.0182 - acc: 0.9954 - val_loss: 0.6013 - val_acc: 0.8641

Epoch 00007: val_loss did not improve from 0.23771
Epoch 8/10
257/257 [==============================] - 510s 2s/step - loss: 0.0084 - acc: 0.9976 - val_loss: 0.5228 - val_acc: 0.8804

Epoch 00008: val_loss did not improve from 0.23771
Found 16504 images belonging to 10 classes.
Found 4724 images belonging to 10 classes.
/home/yilonghao/ml/venv/lib/python3.5/site-packages/keras_applications/resnet50.py:263: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.
  warnings.warn('The output shape of `ResNet50(include_top=False)` '
1: input_2
2: lambda_4
3: conv1_pad
4: conv1
5: bn_conv1
6: activation_95
7: max_pooling2d_5
8: res2a_branch2a
9: bn2a_branch2a
10: activation_96
11: res2a_branch2b
12: bn2a_branch2b
13: activation_97
14: res2a_branch2c
15: res2a_branch1
16: bn2a_branch2c
17: bn2a_branch1
18: add_1
19: activation_98
20: res2b_branch2a
21: bn2b_branch2a
22: activation_99
23: res2b_branch2b
24: bn2b_branch2b
25: activation_100
26: res2b_branch2c
27: bn2b_branch2c
28: add_2
29: activation_101
30: res2c_branch2a
31: bn2c_branch2a
32: activation_102
33: res2c_branch2b
34: bn2c_branch2b
35: activation_103
36: res2c_branch2c
37: bn2c_branch2c
38: add_3
39: activation_104
40: res3a_branch2a
41: bn3a_branch2a
42: activation_105
43: res3a_branch2b
44: bn3a_branch2b
45: activation_106
46: res3a_branch2c
47: res3a_branch1
48: bn3a_branch2c
49: bn3a_branch1
50: add_4
51: activation_107
52: res3b_branch2a
53: bn3b_branch2a
54: activation_108
55: res3b_branch2b
56: bn3b_branch2b
57: activation_109
58: res3b_branch2c
59: bn3b_branch2c
60: add_5
61: activation_110
62: res3c_branch2a
63: bn3c_branch2a
64: activation_111
65: res3c_branch2b
66: bn3c_branch2b
67: activation_112
68: res3c_branch2c
69: bn3c_branch2c
70: add_6
71: activation_113
72: res3d_branch2a
73: bn3d_branch2a
74: activation_114
75: res3d_branch2b
76: bn3d_branch2b
77: activation_115
78: res3d_branch2c
79: bn3d_branch2c
80: add_7
81: activation_116
82: res4a_branch2a
83: bn4a_branch2a
84: activation_117
85: res4a_branch2b
86: bn4a_branch2b
87: activation_118
88: res4a_branch2c
89: res4a_branch1
90: bn4a_branch2c
91: bn4a_branch1
92: add_8
93: activation_119
94: res4b_branch2a
95: bn4b_branch2a
96: activation_120
97: res4b_branch2b
98: bn4b_branch2b
99: activation_121
100: res4b_branch2c
101: bn4b_branch2c
102: add_9
103: activation_122
104: res4c_branch2a
105: bn4c_branch2a
106: activation_123
107: res4c_branch2b
108: bn4c_branch2b
109: activation_124
110: res4c_branch2c
111: bn4c_branch2c
112: add_10
113: activation_125
114: res4d_branch2a
115: bn4d_branch2a
116: activation_126
117: res4d_branch2b
118: bn4d_branch2b
119: activation_127
120: res4d_branch2c
121: bn4d_branch2c
122: add_11
123: activation_128
124: res4e_branch2a
125: bn4e_branch2a
126: activation_129
127: res4e_branch2b
128: bn4e_branch2b
129: activation_130
130: res4e_branch2c
131: bn4e_branch2c
132: add_12
133: activation_131
134: res4f_branch2a
135: bn4f_branch2a
136: activation_132
137: res4f_branch2b
138: bn4f_branch2b
139: activation_133
140: res4f_branch2c
141: bn4f_branch2c
142: add_13
143: activation_134
144: res5a_branch2a
145: bn5a_branch2a
146: activation_135
147: res5a_branch2b
148: bn5a_branch2b
149: activation_136
150: res5a_branch2c
151: res5a_branch1
152: bn5a_branch2c
153: bn5a_branch1
154: add_14
155: activation_137
156: res5b_branch2a
157: bn5b_branch2a
158: activation_138
159: res5b_branch2b
160: bn5b_branch2b
161: activation_139
162: res5b_branch2c
163: bn5b_branch2c
164: add_15
165: activation_140
166: res5c_branch2a
167: bn5c_branch2a
168: activation_141
169: res5c_branch2b
170: bn5c_branch2b
171: activation_142
172: res5c_branch2c
173: bn5c_branch2c
174: add_16
175: activation_143
176: global_average_pooling2d_2
177: dropout_2
178: dense_2
Epoch 1/10
257/257 [==============================] - 529s 2s/step - loss: 0.2325 - acc: 0.9332 - val_loss: 0.3609 - val_acc: 0.9242

Epoch 00001: val_loss improved from inf to 0.36093, saving model to model/resnet50-finetune.hdf5
Epoch 2/10
257/257 [==============================] - 500s 2s/step - loss: 0.0074 - acc: 0.9986 - val_loss: 0.3081 - val_acc: 0.9390

Epoch 00002: val_loss improved from 0.36093 to 0.30807, saving model to model/resnet50-finetune.hdf5
Epoch 3/10
257/257 [==============================] - 510s 2s/step - loss: 0.0056 - acc: 0.9989 - val_loss: 0.2596 - val_acc: 0.9352

Epoch 00003: val_loss improved from 0.30807 to 0.25960, saving model to model/resnet50-finetune.hdf5
Epoch 4/10
257/257 [==============================] - 509s 2s/step - loss: 0.0124 - acc: 0.9967 - val_loss: 0.3687 - val_acc: 0.8838

Epoch 00004: val_loss did not improve from 0.25960
Epoch 5/10
257/257 [==============================] - 512s 2s/step - loss: 0.0055 - acc: 0.9987 - val_loss: 0.2521 - val_acc: 0.9384

Epoch 00005: val_loss improved from 0.25960 to 0.25210, saving model to model/resnet50-finetune.hdf5
Epoch 6/10
257/257 [==============================] - 505s 2s/step - loss: 0.0024 - acc: 0.9994 - val_loss: 0.3485 - val_acc: 0.9259

Epoch 00006: val_loss did not improve from 0.25210
Epoch 7/10
257/257 [==============================] - 507s 2s/step - loss: 0.0028 - acc: 0.9992 - val_loss: 0.7186 - val_acc: 0.8499

Epoch 00007: val_loss did not improve from 0.25210
Epoch 8/10
257/257 [==============================] - 504s 2s/step - loss: 0.0130 - acc: 0.9965 - val_loss: 0.3979 - val_acc: 0.8948

Epoch 00008: val_loss did not improve from 0.25210
Found 16504 images belonging to 10 classes.
Found 4724 images belonging to 10 classes.
1: input_3
2: lambda_7
3: block1_conv1
4: block1_conv1_bn
5: block1_conv1_act
6: block1_conv2
7: block1_conv2_bn
8: block1_conv2_act
9: block2_sepconv1
10: block2_sepconv1_bn
11: block2_sepconv2_act
12: block2_sepconv2
13: block2_sepconv2_bn
14: conv2d_95
15: block2_pool
16: batch_normalization_95
17: add_17
18: block3_sepconv1_act
19: block3_sepconv1
20: block3_sepconv1_bn
21: block3_sepconv2_act
22: block3_sepconv2
23: block3_sepconv2_bn
24: conv2d_96
25: block3_pool
26: batch_normalization_96
27: add_18
28: block4_sepconv1_act
29: block4_sepconv1
30: block4_sepconv1_bn
31: block4_sepconv2_act
32: block4_sepconv2
33: block4_sepconv2_bn
34: conv2d_97
35: block4_pool
36: batch_normalization_97
37: add_19
38: block5_sepconv1_act
39: block5_sepconv1
40: block5_sepconv1_bn
41: block5_sepconv2_act
42: block5_sepconv2
43: block5_sepconv2_bn
44: block5_sepconv3_act
45: block5_sepconv3
46: block5_sepconv3_bn
47: add_20
48: block6_sepconv1_act
49: block6_sepconv1
50: block6_sepconv1_bn
51: block6_sepconv2_act
52: block6_sepconv2
53: block6_sepconv2_bn
54: block6_sepconv3_act
55: block6_sepconv3
56: block6_sepconv3_bn
57: add_21
58: block7_sepconv1_act
59: block7_sepconv1
60: block7_sepconv1_bn
61: block7_sepconv2_act
62: block7_sepconv2
63: block7_sepconv2_bn
64: block7_sepconv3_act
65: block7_sepconv3
66: block7_sepconv3_bn
67: add_22
68: block8_sepconv1_act
69: block8_sepconv1
70: block8_sepconv1_bn
71: block8_sepconv2_act
72: block8_sepconv2
73: block8_sepconv2_bn
74: block8_sepconv3_act
75: block8_sepconv3
76: block8_sepconv3_bn
77: add_23
78: block9_sepconv1_act
79: block9_sepconv1
80: block9_sepconv1_bn
81: block9_sepconv2_act
82: block9_sepconv2
83: block9_sepconv2_bn
84: block9_sepconv3_act
85: block9_sepconv3
86: block9_sepconv3_bn
87: add_24
88: block10_sepconv1_act
89: block10_sepconv1
90: block10_sepconv1_bn
91: block10_sepconv2_act
92: block10_sepconv2
93: block10_sepconv2_bn
94: block10_sepconv3_act
95: block10_sepconv3
96: block10_sepconv3_bn
97: add_25
98: block11_sepconv1_act
99: block11_sepconv1
100: block11_sepconv1_bn
101: block11_sepconv2_act
102: block11_sepconv2
103: block11_sepconv2_bn
104: block11_sepconv3_act
105: block11_sepconv3
106: block11_sepconv3_bn
107: add_26
108: block12_sepconv1_act
109: block12_sepconv1
110: block12_sepconv1_bn
111: block12_sepconv2_act
112: block12_sepconv2
113: block12_sepconv2_bn
114: block12_sepconv3_act
115: block12_sepconv3
116: block12_sepconv3_bn
117: add_27
118: block13_sepconv1_act
119: block13_sepconv1
120: block13_sepconv1_bn
121: block13_sepconv2_act
122: block13_sepconv2
123: block13_sepconv2_bn
124: conv2d_98
125: block13_pool
126: batch_normalization_98
127: add_28
128: block14_sepconv1
129: block14_sepconv1_bn
130: block14_sepconv1_act
131: block14_sepconv2
132: block14_sepconv2_bn
133: block14_sepconv2_act
134: global_average_pooling2d_3
135: dropout_3
136: dense_3
Epoch 1/10
257/257 [==============================] - 521s 2s/step - loss: 0.4371 - acc: 0.8923 - val_loss: 0.3679 - val_acc: 0.9009

Epoch 00001: val_loss improved from inf to 0.36788, saving model to model/xception-finetune.hdf5
Epoch 2/10
257/257 [==============================] - 502s 2s/step - loss: 0.0184 - acc: 0.9968 - val_loss: 0.3661 - val_acc: 0.8882

Epoch 00002: val_loss improved from 0.36788 to 0.36613, saving model to model/xception-finetune.hdf5
Epoch 3/10
257/257 [==============================] - 505s 2s/step - loss: 0.0058 - acc: 0.9991 - val_loss: 0.4321 - val_acc: 0.8618

Epoch 00003: val_loss did not improve from 0.36613
Epoch 4/10
257/257 [==============================] - 503s 2s/step - loss: 0.0020 - acc: 0.9999 - val_loss: 0.4668 - val_acc: 0.8563

Epoch 00004: val_loss did not improve from 0.36613
Epoch 5/10
257/257 [==============================] - 504s 2s/step - loss: 0.0019 - acc: 0.9997 - val_loss: 0.4222 - val_acc: 0.8671

Epoch 00005: val_loss did not improve from 0.36613
Found 16504 images belonging to 10 classes.
Found 4724 images belonging to 10 classes.
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to
==================================================================================================
input_4 (InputLayer)            (None, 480, 480, 3)  0
__________________________________________________________________________________________________
lambda_10 (Lambda)              (None, 480, 480, 3)  0           input_4[0][0]
__________________________________________________________________________________________________
block1_conv1 (Conv2D)           (None, 239, 239, 32) 864         lambda_10[0][0]
__________________________________________________________________________________________________
block1_conv1_bn (BatchNormaliza (None, 239, 239, 32) 128         block1_conv1[0][0]
__________________________________________________________________________________________________
block1_conv1_act (Activation)   (None, 239, 239, 32) 0           block1_conv1_bn[0][0]
__________________________________________________________________________________________________
block1_conv2 (Conv2D)           (None, 237, 237, 64) 18432       block1_conv1_act[0][0]
__________________________________________________________________________________________________
block1_conv2_bn (BatchNormaliza (None, 237, 237, 64) 256         block1_conv2[0][0]
__________________________________________________________________________________________________
block1_conv2_act (Activation)   (None, 237, 237, 64) 0           block1_conv2_bn[0][0]
__________________________________________________________________________________________________
block2_sepconv1 (SeparableConv2 (None, 237, 237, 128 8768        block1_conv2_act[0][0]
__________________________________________________________________________________________________
block2_sepconv1_bn (BatchNormal (None, 237, 237, 128 512         block2_sepconv1[0][0]
__________________________________________________________________________________________________
block2_sepconv2_act (Activation (None, 237, 237, 128 0           block2_sepconv1_bn[0][0]
__________________________________________________________________________________________________
block2_sepconv2 (SeparableConv2 (None, 237, 237, 128 17536       block2_sepconv2_act[0][0]
__________________________________________________________________________________________________
block2_sepconv2_bn (BatchNormal (None, 237, 237, 128 512         block2_sepconv2[0][0]
__________________________________________________________________________________________________
conv2d_99 (Conv2D)              (None, 119, 119, 128 8192        block1_conv2_act[0][0]
__________________________________________________________________________________________________
block2_pool (MaxPooling2D)      (None, 119, 119, 128 0           block2_sepconv2_bn[0][0]
__________________________________________________________________________________________________
batch_normalization_99 (BatchNo (None, 119, 119, 128 512         conv2d_99[0][0]
__________________________________________________________________________________________________
add_29 (Add)                    (None, 119, 119, 128 0           block2_pool[0][0]
                                                                 batch_normalization_99[0][0]
__________________________________________________________________________________________________
block3_sepconv1_act (Activation (None, 119, 119, 128 0           add_29[0][0]
__________________________________________________________________________________________________
block3_sepconv1 (SeparableConv2 (None, 119, 119, 256 33920       block3_sepconv1_act[0][0]
__________________________________________________________________________________________________
block3_sepconv1_bn (BatchNormal (None, 119, 119, 256 1024        block3_sepconv1[0][0]
__________________________________________________________________________________________________
block3_sepconv2_act (Activation (None, 119, 119, 256 0           block3_sepconv1_bn[0][0]
__________________________________________________________________________________________________
block3_sepconv2 (SeparableConv2 (None, 119, 119, 256 67840       block3_sepconv2_act[0][0]
__________________________________________________________________________________________________
block3_sepconv2_bn (BatchNormal (None, 119, 119, 256 1024        block3_sepconv2[0][0]
__________________________________________________________________________________________________
conv2d_100 (Conv2D)             (None, 60, 60, 256)  32768       add_29[0][0]
__________________________________________________________________________________________________
block3_pool (MaxPooling2D)      (None, 60, 60, 256)  0           block3_sepconv2_bn[0][0]
__________________________________________________________________________________________________
batch_normalization_100 (BatchN (None, 60, 60, 256)  1024        conv2d_100[0][0]
__________________________________________________________________________________________________
add_30 (Add)                    (None, 60, 60, 256)  0           block3_pool[0][0]
                                                                 batch_normalization_100[0][0]
__________________________________________________________________________________________________
block4_sepconv1_act (Activation (None, 60, 60, 256)  0           add_30[0][0]
__________________________________________________________________________________________________
block4_sepconv1 (SeparableConv2 (None, 60, 60, 728)  188672      block4_sepconv1_act[0][0]
__________________________________________________________________________________________________
block4_sepconv1_bn (BatchNormal (None, 60, 60, 728)  2912        block4_sepconv1[0][0]
__________________________________________________________________________________________________
block4_sepconv2_act (Activation (None, 60, 60, 728)  0           block4_sepconv1_bn[0][0]
__________________________________________________________________________________________________
block4_sepconv2 (SeparableConv2 (None, 60, 60, 728)  536536      block4_sepconv2_act[0][0]
__________________________________________________________________________________________________
block4_sepconv2_bn (BatchNormal (None, 60, 60, 728)  2912        block4_sepconv2[0][0]
__________________________________________________________________________________________________
conv2d_101 (Conv2D)             (None, 30, 30, 728)  186368      add_30[0][0]
__________________________________________________________________________________________________
block4_pool (MaxPooling2D)      (None, 30, 30, 728)  0           block4_sepconv2_bn[0][0]
__________________________________________________________________________________________________
batch_normalization_101 (BatchN (None, 30, 30, 728)  2912        conv2d_101[0][0]
__________________________________________________________________________________________________
add_31 (Add)                    (None, 30, 30, 728)  0           block4_pool[0][0]
                                                                 batch_normalization_101[0][0]
__________________________________________________________________________________________________
block5_sepconv1_act (Activation (None, 30, 30, 728)  0           add_31[0][0]
__________________________________________________________________________________________________
block5_sepconv1 (SeparableConv2 (None, 30, 30, 728)  536536      block5_sepconv1_act[0][0]
__________________________________________________________________________________________________
block5_sepconv1_bn (BatchNormal (None, 30, 30, 728)  2912        block5_sepconv1[0][0]
__________________________________________________________________________________________________
block5_sepconv2_act (Activation (None, 30, 30, 728)  0           block5_sepconv1_bn[0][0]
__________________________________________________________________________________________________
block5_sepconv2 (SeparableConv2 (None, 30, 30, 728)  536536      block5_sepconv2_act[0][0]
__________________________________________________________________________________________________
block5_sepconv2_bn (BatchNormal (None, 30, 30, 728)  2912        block5_sepconv2[0][0]
__________________________________________________________________________________________________
block5_sepconv3_act (Activation (None, 30, 30, 728)  0           block5_sepconv2_bn[0][0]
__________________________________________________________________________________________________
block5_sepconv3 (SeparableConv2 (None, 30, 30, 728)  536536      block5_sepconv3_act[0][0]
__________________________________________________________________________________________________
block5_sepconv3_bn (BatchNormal (None, 30, 30, 728)  2912        block5_sepconv3[0][0]
__________________________________________________________________________________________________
add_32 (Add)                    (None, 30, 30, 728)  0           block5_sepconv3_bn[0][0]
                                                                 add_31[0][0]
__________________________________________________________________________________________________
block6_sepconv1_act (Activation (None, 30, 30, 728)  0           add_32[0][0]
__________________________________________________________________________________________________
block6_sepconv1 (SeparableConv2 (None, 30, 30, 728)  536536      block6_sepconv1_act[0][0]
__________________________________________________________________________________________________
block6_sepconv1_bn (BatchNormal (None, 30, 30, 728)  2912        block6_sepconv1[0][0]
__________________________________________________________________________________________________
block6_sepconv2_act (Activation (None, 30, 30, 728)  0           block6_sepconv1_bn[0][0]
__________________________________________________________________________________________________
block6_sepconv2 (SeparableConv2 (None, 30, 30, 728)  536536      block6_sepconv2_act[0][0]
__________________________________________________________________________________________________
block6_sepconv2_bn (BatchNormal (None, 30, 30, 728)  2912        block6_sepconv2[0][0]
__________________________________________________________________________________________________
block6_sepconv3_act (Activation (None, 30, 30, 728)  0           block6_sepconv2_bn[0][0]
__________________________________________________________________________________________________
block6_sepconv3 (SeparableConv2 (None, 30, 30, 728)  536536      block6_sepconv3_act[0][0]
__________________________________________________________________________________________________
block6_sepconv3_bn (BatchNormal (None, 30, 30, 728)  2912        block6_sepconv3[0][0]
__________________________________________________________________________________________________
add_33 (Add)                    (None, 30, 30, 728)  0           block6_sepconv3_bn[0][0]
                                                                 add_32[0][0]
__________________________________________________________________________________________________
block7_sepconv1_act (Activation (None, 30, 30, 728)  0           add_33[0][0]
__________________________________________________________________________________________________
block7_sepconv1 (SeparableConv2 (None, 30, 30, 728)  536536      block7_sepconv1_act[0][0]
__________________________________________________________________________________________________
block7_sepconv1_bn (BatchNormal (None, 30, 30, 728)  2912        block7_sepconv1[0][0]
__________________________________________________________________________________________________
block7_sepconv2_act (Activation (None, 30, 30, 728)  0           block7_sepconv1_bn[0][0]
__________________________________________________________________________________________________
block7_sepconv2 (SeparableConv2 (None, 30, 30, 728)  536536      block7_sepconv2_act[0][0]
__________________________________________________________________________________________________
block7_sepconv2_bn (BatchNormal (None, 30, 30, 728)  2912        block7_sepconv2[0][0]
__________________________________________________________________________________________________
block7_sepconv3_act (Activation (None, 30, 30, 728)  0           block7_sepconv2_bn[0][0]
__________________________________________________________________________________________________
block7_sepconv3 (SeparableConv2 (None, 30, 30, 728)  536536      block7_sepconv3_act[0][0]
__________________________________________________________________________________________________
block7_sepconv3_bn (BatchNormal (None, 30, 30, 728)  2912        block7_sepconv3[0][0]
__________________________________________________________________________________________________
add_34 (Add)                    (None, 30, 30, 728)  0           block7_sepconv3_bn[0][0]
                                                                 add_33[0][0]
__________________________________________________________________________________________________
block8_sepconv1_act (Activation (None, 30, 30, 728)  0           add_34[0][0]
__________________________________________________________________________________________________
block8_sepconv1 (SeparableConv2 (None, 30, 30, 728)  536536      block8_sepconv1_act[0][0]
__________________________________________________________________________________________________
block8_sepconv1_bn (BatchNormal (None, 30, 30, 728)  2912        block8_sepconv1[0][0]
__________________________________________________________________________________________________
block8_sepconv2_act (Activation (None, 30, 30, 728)  0           block8_sepconv1_bn[0][0]
__________________________________________________________________________________________________
block8_sepconv2 (SeparableConv2 (None, 30, 30, 728)  536536      block8_sepconv2_act[0][0]
__________________________________________________________________________________________________
block8_sepconv2_bn (BatchNormal (None, 30, 30, 728)  2912        block8_sepconv2[0][0]
__________________________________________________________________________________________________
block8_sepconv3_act (Activation (None, 30, 30, 728)  0           block8_sepconv2_bn[0][0]
__________________________________________________________________________________________________
block8_sepconv3 (SeparableConv2 (None, 30, 30, 728)  536536      block8_sepconv3_act[0][0]
__________________________________________________________________________________________________
block8_sepconv3_bn (BatchNormal (None, 30, 30, 728)  2912        block8_sepconv3[0][0]
__________________________________________________________________________________________________
add_35 (Add)                    (None, 30, 30, 728)  0           block8_sepconv3_bn[0][0]
                                                                 add_34[0][0]
__________________________________________________________________________________________________
block9_sepconv1_act (Activation (None, 30, 30, 728)  0           add_35[0][0]
__________________________________________________________________________________________________
block9_sepconv1 (SeparableConv2 (None, 30, 30, 728)  536536      block9_sepconv1_act[0][0]
__________________________________________________________________________________________________
block9_sepconv1_bn (BatchNormal (None, 30, 30, 728)  2912        block9_sepconv1[0][0]
__________________________________________________________________________________________________
block9_sepconv2_act (Activation (None, 30, 30, 728)  0           block9_sepconv1_bn[0][0]
__________________________________________________________________________________________________
block9_sepconv2 (SeparableConv2 (None, 30, 30, 728)  536536      block9_sepconv2_act[0][0]
__________________________________________________________________________________________________
block9_sepconv2_bn (BatchNormal (None, 30, 30, 728)  2912        block9_sepconv2[0][0]
__________________________________________________________________________________________________
block9_sepconv3_act (Activation (None, 30, 30, 728)  0           block9_sepconv2_bn[0][0]
__________________________________________________________________________________________________
block9_sepconv3 (SeparableConv2 (None, 30, 30, 728)  536536      block9_sepconv3_act[0][0]
__________________________________________________________________________________________________
block9_sepconv3_bn (BatchNormal (None, 30, 30, 728)  2912        block9_sepconv3[0][0]
__________________________________________________________________________________________________
add_36 (Add)                    (None, 30, 30, 728)  0           block9_sepconv3_bn[0][0]
                                                                 add_35[0][0]
__________________________________________________________________________________________________
block10_sepconv1_act (Activatio (None, 30, 30, 728)  0           add_36[0][0]
__________________________________________________________________________________________________
block10_sepconv1 (SeparableConv (None, 30, 30, 728)  536536      block10_sepconv1_act[0][0]
__________________________________________________________________________________________________
block10_sepconv1_bn (BatchNorma (None, 30, 30, 728)  2912        block10_sepconv1[0][0]
__________________________________________________________________________________________________
block10_sepconv2_act (Activatio (None, 30, 30, 728)  0           block10_sepconv1_bn[0][0]
__________________________________________________________________________________________________
block10_sepconv2 (SeparableConv (None, 30, 30, 728)  536536      block10_sepconv2_act[0][0]
__________________________________________________________________________________________________
block10_sepconv2_bn (BatchNorma (None, 30, 30, 728)  2912        block10_sepconv2[0][0]
__________________________________________________________________________________________________
block10_sepconv3_act (Activatio (None, 30, 30, 728)  0           block10_sepconv2_bn[0][0]
__________________________________________________________________________________________________
block10_sepconv3 (SeparableConv (None, 30, 30, 728)  536536      block10_sepconv3_act[0][0]
__________________________________________________________________________________________________
block10_sepconv3_bn (BatchNorma (None, 30, 30, 728)  2912        block10_sepconv3[0][0]
__________________________________________________________________________________________________
add_37 (Add)                    (None, 30, 30, 728)  0           block10_sepconv3_bn[0][0]
                                                                 add_36[0][0]
__________________________________________________________________________________________________
block11_sepconv1_act (Activatio (None, 30, 30, 728)  0           add_37[0][0]
__________________________________________________________________________________________________
block11_sepconv1 (SeparableConv (None, 30, 30, 728)  536536      block11_sepconv1_act[0][0]
__________________________________________________________________________________________________
block11_sepconv1_bn (BatchNorma (None, 30, 30, 728)  2912        block11_sepconv1[0][0]
__________________________________________________________________________________________________
block11_sepconv2_act (Activatio (None, 30, 30, 728)  0           block11_sepconv1_bn[0][0]
__________________________________________________________________________________________________
block11_sepconv2 (SeparableConv (None, 30, 30, 728)  536536      block11_sepconv2_act[0][0]
__________________________________________________________________________________________________
block11_sepconv2_bn (BatchNorma (None, 30, 30, 728)  2912        block11_sepconv2[0][0]
__________________________________________________________________________________________________
block11_sepconv3_act (Activatio (None, 30, 30, 728)  0           block11_sepconv2_bn[0][0]
__________________________________________________________________________________________________
block11_sepconv3 (SeparableConv (None, 30, 30, 728)  536536      block11_sepconv3_act[0][0]
__________________________________________________________________________________________________
block11_sepconv3_bn (BatchNorma (None, 30, 30, 728)  2912        block11_sepconv3[0][0]
__________________________________________________________________________________________________
add_38 (Add)                    (None, 30, 30, 728)  0           block11_sepconv3_bn[0][0]
                                                                 add_37[0][0]
__________________________________________________________________________________________________
block12_sepconv1_act (Activatio (None, 30, 30, 728)  0           add_38[0][0]
__________________________________________________________________________________________________
block12_sepconv1 (SeparableConv (None, 30, 30, 728)  536536      block12_sepconv1_act[0][0]
__________________________________________________________________________________________________
block12_sepconv1_bn (BatchNorma (None, 30, 30, 728)  2912        block12_sepconv1[0][0]
__________________________________________________________________________________________________
block12_sepconv2_act (Activatio (None, 30, 30, 728)  0           block12_sepconv1_bn[0][0]
__________________________________________________________________________________________________
block12_sepconv2 (SeparableConv (None, 30, 30, 728)  536536      block12_sepconv2_act[0][0]
__________________________________________________________________________________________________
block12_sepconv2_bn (BatchNorma (None, 30, 30, 728)  2912        block12_sepconv2[0][0]
__________________________________________________________________________________________________
block12_sepconv3_act (Activatio (None, 30, 30, 728)  0           block12_sepconv2_bn[0][0]
__________________________________________________________________________________________________
block12_sepconv3 (SeparableConv (None, 30, 30, 728)  536536      block12_sepconv3_act[0][0]
__________________________________________________________________________________________________
block12_sepconv3_bn (BatchNorma (None, 30, 30, 728)  2912        block12_sepconv3[0][0]
__________________________________________________________________________________________________
add_39 (Add)                    (None, 30, 30, 728)  0           block12_sepconv3_bn[0][0]
                                                                 add_38[0][0]
__________________________________________________________________________________________________
block13_sepconv1_act (Activatio (None, 30, 30, 728)  0           add_39[0][0]
__________________________________________________________________________________________________
block13_sepconv1 (SeparableConv (None, 30, 30, 728)  536536      block13_sepconv1_act[0][0]
__________________________________________________________________________________________________
block13_sepconv1_bn (BatchNorma (None, 30, 30, 728)  2912        block13_sepconv1[0][0]
__________________________________________________________________________________________________
block13_sepconv2_act (Activatio (None, 30, 30, 728)  0           block13_sepconv1_bn[0][0]
__________________________________________________________________________________________________
block13_sepconv2 (SeparableConv (None, 30, 30, 1024) 752024      block13_sepconv2_act[0][0]
__________________________________________________________________________________________________
block13_sepconv2_bn (BatchNorma (None, 30, 30, 1024) 4096        block13_sepconv2[0][0]
__________________________________________________________________________________________________
conv2d_102 (Conv2D)             (None, 15, 15, 1024) 745472      add_39[0][0]
__________________________________________________________________________________________________
block13_pool (MaxPooling2D)     (None, 15, 15, 1024) 0           block13_sepconv2_bn[0][0]
__________________________________________________________________________________________________
batch_normalization_102 (BatchN (None, 15, 15, 1024) 4096        conv2d_102[0][0]
__________________________________________________________________________________________________
add_40 (Add)                    (None, 15, 15, 1024) 0           block13_pool[0][0]
                                                                 batch_normalization_102[0][0]
__________________________________________________________________________________________________
block14_sepconv1 (SeparableConv (None, 15, 15, 1536) 1582080     add_40[0][0]
__________________________________________________________________________________________________
block14_sepconv1_bn (BatchNorma (None, 15, 15, 1536) 6144        block14_sepconv1[0][0]
__________________________________________________________________________________________________
block14_sepconv1_act (Activatio (None, 15, 15, 1536) 0           block14_sepconv1_bn[0][0]
__________________________________________________________________________________________________
block14_sepconv2 (SeparableConv (None, 15, 15, 2048) 3159552     block14_sepconv1_act[0][0]
__________________________________________________________________________________________________
block14_sepconv2_bn (BatchNorma (None, 15, 15, 2048) 8192        block14_sepconv2[0][0]
__________________________________________________________________________________________________
block14_sepconv2_act (Activatio (None, 15, 15, 2048) 0           block14_sepconv2_bn[0][0]
__________________________________________________________________________________________________
global_average_pooling2d_4 (Glo (None, 2048)         0           block14_sepconv2_act[0][0]
==================================================================================================
Total params: 20,861,480
Trainable params: 20,806,952
Non-trainable params: 54,528
__________________________________________________________________________________________________
257/257 [==============================] - 332s 1s/step
73/73 [==============================] - 103s 1s/step
/home/yilonghao/ml/venv/lib/python3.5/site-packages/keras_applications/resnet50.py:263: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.
  warnings.warn('The output shape of `ResNet50(include_top=False)` '
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to
==================================================================================================
input_5 (InputLayer)            (None, 480, 480, 3)  0
__________________________________________________________________________________________________
lambda_11 (Lambda)              (None, 480, 480, 3)  0           input_5[0][0]
__________________________________________________________________________________________________
conv1_pad (ZeroPadding2D)       (None, 486, 486, 3)  0           lambda_11[0][0]
__________________________________________________________________________________________________
conv1 (Conv2D)                  (None, 240, 240, 64) 9472        conv1_pad[0][0]
__________________________________________________________________________________________________
bn_conv1 (BatchNormalization)   (None, 240, 240, 64) 256         conv1[0][0]
__________________________________________________________________________________________________
activation_144 (Activation)     (None, 240, 240, 64) 0           bn_conv1[0][0]
__________________________________________________________________________________________________
max_pooling2d_6 (MaxPooling2D)  (None, 119, 119, 64) 0           activation_144[0][0]
__________________________________________________________________________________________________
res2a_branch2a (Conv2D)         (None, 119, 119, 64) 4160        max_pooling2d_6[0][0]
__________________________________________________________________________________________________
bn2a_branch2a (BatchNormalizati (None, 119, 119, 64) 256         res2a_branch2a[0][0]
__________________________________________________________________________________________________
activation_145 (Activation)     (None, 119, 119, 64) 0           bn2a_branch2a[0][0]
__________________________________________________________________________________________________
res2a_branch2b (Conv2D)         (None, 119, 119, 64) 36928       activation_145[0][0]
__________________________________________________________________________________________________
bn2a_branch2b (BatchNormalizati (None, 119, 119, 64) 256         res2a_branch2b[0][0]
__________________________________________________________________________________________________
activation_146 (Activation)     (None, 119, 119, 64) 0           bn2a_branch2b[0][0]
__________________________________________________________________________________________________
res2a_branch2c (Conv2D)         (None, 119, 119, 256 16640       activation_146[0][0]
__________________________________________________________________________________________________
res2a_branch1 (Conv2D)          (None, 119, 119, 256 16640       max_pooling2d_6[0][0]
__________________________________________________________________________________________________
bn2a_branch2c (BatchNormalizati (None, 119, 119, 256 1024        res2a_branch2c[0][0]
__________________________________________________________________________________________________
bn2a_branch1 (BatchNormalizatio (None, 119, 119, 256 1024        res2a_branch1[0][0]
__________________________________________________________________________________________________
add_41 (Add)                    (None, 119, 119, 256 0           bn2a_branch2c[0][0]
                                                                 bn2a_branch1[0][0]
__________________________________________________________________________________________________
activation_147 (Activation)     (None, 119, 119, 256 0           add_41[0][0]
__________________________________________________________________________________________________
res2b_branch2a (Conv2D)         (None, 119, 119, 64) 16448       activation_147[0][0]
__________________________________________________________________________________________________
bn2b_branch2a (BatchNormalizati (None, 119, 119, 64) 256         res2b_branch2a[0][0]
__________________________________________________________________________________________________
activation_148 (Activation)     (None, 119, 119, 64) 0           bn2b_branch2a[0][0]
__________________________________________________________________________________________________
res2b_branch2b (Conv2D)         (None, 119, 119, 64) 36928       activation_148[0][0]
__________________________________________________________________________________________________
bn2b_branch2b (BatchNormalizati (None, 119, 119, 64) 256         res2b_branch2b[0][0]
__________________________________________________________________________________________________
activation_149 (Activation)     (None, 119, 119, 64) 0           bn2b_branch2b[0][0]
__________________________________________________________________________________________________
res2b_branch2c (Conv2D)         (None, 119, 119, 256 16640       activation_149[0][0]
__________________________________________________________________________________________________
bn2b_branch2c (BatchNormalizati (None, 119, 119, 256 1024        res2b_branch2c[0][0]
__________________________________________________________________________________________________
add_42 (Add)                    (None, 119, 119, 256 0           bn2b_branch2c[0][0]
                                                                 activation_147[0][0]
__________________________________________________________________________________________________
activation_150 (Activation)     (None, 119, 119, 256 0           add_42[0][0]
__________________________________________________________________________________________________
res2c_branch2a (Conv2D)         (None, 119, 119, 64) 16448       activation_150[0][0]
__________________________________________________________________________________________________
bn2c_branch2a (BatchNormalizati (None, 119, 119, 64) 256         res2c_branch2a[0][0]
__________________________________________________________________________________________________
activation_151 (Activation)     (None, 119, 119, 64) 0           bn2c_branch2a[0][0]
__________________________________________________________________________________________________
res2c_branch2b (Conv2D)         (None, 119, 119, 64) 36928       activation_151[0][0]
__________________________________________________________________________________________________
bn2c_branch2b (BatchNormalizati (None, 119, 119, 64) 256         res2c_branch2b[0][0]
__________________________________________________________________________________________________
activation_152 (Activation)     (None, 119, 119, 64) 0           bn2c_branch2b[0][0]
__________________________________________________________________________________________________
res2c_branch2c (Conv2D)         (None, 119, 119, 256 16640       activation_152[0][0]
__________________________________________________________________________________________________
bn2c_branch2c (BatchNormalizati (None, 119, 119, 256 1024        res2c_branch2c[0][0]
__________________________________________________________________________________________________
add_43 (Add)                    (None, 119, 119, 256 0           bn2c_branch2c[0][0]
                                                                 activation_150[0][0]
__________________________________________________________________________________________________
activation_153 (Activation)     (None, 119, 119, 256 0           add_43[0][0]
__________________________________________________________________________________________________
res3a_branch2a (Conv2D)         (None, 60, 60, 128)  32896       activation_153[0][0]
__________________________________________________________________________________________________
bn3a_branch2a (BatchNormalizati (None, 60, 60, 128)  512         res3a_branch2a[0][0]
__________________________________________________________________________________________________
activation_154 (Activation)     (None, 60, 60, 128)  0           bn3a_branch2a[0][0]
__________________________________________________________________________________________________
res3a_branch2b (Conv2D)         (None, 60, 60, 128)  147584      activation_154[0][0]
__________________________________________________________________________________________________
bn3a_branch2b (BatchNormalizati (None, 60, 60, 128)  512         res3a_branch2b[0][0]
__________________________________________________________________________________________________
activation_155 (Activation)     (None, 60, 60, 128)  0           bn3a_branch2b[0][0]
__________________________________________________________________________________________________
res3a_branch2c (Conv2D)         (None, 60, 60, 512)  66048       activation_155[0][0]
__________________________________________________________________________________________________
res3a_branch1 (Conv2D)          (None, 60, 60, 512)  131584      activation_153[0][0]
__________________________________________________________________________________________________
bn3a_branch2c (BatchNormalizati (None, 60, 60, 512)  2048        res3a_branch2c[0][0]
__________________________________________________________________________________________________
bn3a_branch1 (BatchNormalizatio (None, 60, 60, 512)  2048        res3a_branch1[0][0]
__________________________________________________________________________________________________
add_44 (Add)                    (None, 60, 60, 512)  0           bn3a_branch2c[0][0]
                                                                 bn3a_branch1[0][0]
__________________________________________________________________________________________________
activation_156 (Activation)     (None, 60, 60, 512)  0           add_44[0][0]
__________________________________________________________________________________________________
res3b_branch2a (Conv2D)         (None, 60, 60, 128)  65664       activation_156[0][0]
__________________________________________________________________________________________________
bn3b_branch2a (BatchNormalizati (None, 60, 60, 128)  512         res3b_branch2a[0][0]
__________________________________________________________________________________________________
activation_157 (Activation)     (None, 60, 60, 128)  0           bn3b_branch2a[0][0]
__________________________________________________________________________________________________
res3b_branch2b (Conv2D)         (None, 60, 60, 128)  147584      activation_157[0][0]
__________________________________________________________________________________________________
bn3b_branch2b (BatchNormalizati (None, 60, 60, 128)  512         res3b_branch2b[0][0]
__________________________________________________________________________________________________
activation_158 (Activation)     (None, 60, 60, 128)  0           bn3b_branch2b[0][0]
__________________________________________________________________________________________________
res3b_branch2c (Conv2D)         (None, 60, 60, 512)  66048       activation_158[0][0]
__________________________________________________________________________________________________
bn3b_branch2c (BatchNormalizati (None, 60, 60, 512)  2048        res3b_branch2c[0][0]
__________________________________________________________________________________________________
add_45 (Add)                    (None, 60, 60, 512)  0           bn3b_branch2c[0][0]
                                                                 activation_156[0][0]
__________________________________________________________________________________________________
activation_159 (Activation)     (None, 60, 60, 512)  0           add_45[0][0]
__________________________________________________________________________________________________
res3c_branch2a (Conv2D)         (None, 60, 60, 128)  65664       activation_159[0][0]
__________________________________________________________________________________________________
bn3c_branch2a (BatchNormalizati (None, 60, 60, 128)  512         res3c_branch2a[0][0]
__________________________________________________________________________________________________
activation_160 (Activation)     (None, 60, 60, 128)  0           bn3c_branch2a[0][0]
__________________________________________________________________________________________________
res3c_branch2b (Conv2D)         (None, 60, 60, 128)  147584      activation_160[0][0]
__________________________________________________________________________________________________
bn3c_branch2b (BatchNormalizati (None, 60, 60, 128)  512         res3c_branch2b[0][0]
__________________________________________________________________________________________________
activation_161 (Activation)     (None, 60, 60, 128)  0           bn3c_branch2b[0][0]
__________________________________________________________________________________________________
res3c_branch2c (Conv2D)         (None, 60, 60, 512)  66048       activation_161[0][0]
__________________________________________________________________________________________________
bn3c_branch2c (BatchNormalizati (None, 60, 60, 512)  2048        res3c_branch2c[0][0]
__________________________________________________________________________________________________
add_46 (Add)                    (None, 60, 60, 512)  0           bn3c_branch2c[0][0]
                                                                 activation_159[0][0]
__________________________________________________________________________________________________
activation_162 (Activation)     (None, 60, 60, 512)  0           add_46[0][0]
__________________________________________________________________________________________________
res3d_branch2a (Conv2D)         (None, 60, 60, 128)  65664       activation_162[0][0]
__________________________________________________________________________________________________
bn3d_branch2a (BatchNormalizati (None, 60, 60, 128)  512         res3d_branch2a[0][0]
__________________________________________________________________________________________________
activation_163 (Activation)     (None, 60, 60, 128)  0           bn3d_branch2a[0][0]
__________________________________________________________________________________________________
res3d_branch2b (Conv2D)         (None, 60, 60, 128)  147584      activation_163[0][0]
__________________________________________________________________________________________________
bn3d_branch2b (BatchNormalizati (None, 60, 60, 128)  512         res3d_branch2b[0][0]
__________________________________________________________________________________________________
activation_164 (Activation)     (None, 60, 60, 128)  0           bn3d_branch2b[0][0]
__________________________________________________________________________________________________
res3d_branch2c (Conv2D)         (None, 60, 60, 512)  66048       activation_164[0][0]
__________________________________________________________________________________________________
bn3d_branch2c (BatchNormalizati (None, 60, 60, 512)  2048        res3d_branch2c[0][0]
__________________________________________________________________________________________________
add_47 (Add)                    (None, 60, 60, 512)  0           bn3d_branch2c[0][0]
                                                                 activation_162[0][0]
__________________________________________________________________________________________________
activation_165 (Activation)     (None, 60, 60, 512)  0           add_47[0][0]
__________________________________________________________________________________________________
res4a_branch2a (Conv2D)         (None, 30, 30, 256)  131328      activation_165[0][0]
__________________________________________________________________________________________________
bn4a_branch2a (BatchNormalizati (None, 30, 30, 256)  1024        res4a_branch2a[0][0]
__________________________________________________________________________________________________
activation_166 (Activation)     (None, 30, 30, 256)  0           bn4a_branch2a[0][0]
__________________________________________________________________________________________________
res4a_branch2b (Conv2D)         (None, 30, 30, 256)  590080      activation_166[0][0]
__________________________________________________________________________________________________
bn4a_branch2b (BatchNormalizati (None, 30, 30, 256)  1024        res4a_branch2b[0][0]
__________________________________________________________________________________________________
activation_167 (Activation)     (None, 30, 30, 256)  0           bn4a_branch2b[0][0]
__________________________________________________________________________________________________
res4a_branch2c (Conv2D)         (None, 30, 30, 1024) 263168      activation_167[0][0]
__________________________________________________________________________________________________
res4a_branch1 (Conv2D)          (None, 30, 30, 1024) 525312      activation_165[0][0]
__________________________________________________________________________________________________
bn4a_branch2c (BatchNormalizati (None, 30, 30, 1024) 4096        res4a_branch2c[0][0]
__________________________________________________________________________________________________
bn4a_branch1 (BatchNormalizatio (None, 30, 30, 1024) 4096        res4a_branch1[0][0]
__________________________________________________________________________________________________
add_48 (Add)                    (None, 30, 30, 1024) 0           bn4a_branch2c[0][0]
                                                                 bn4a_branch1[0][0]
__________________________________________________________________________________________________
activation_168 (Activation)     (None, 30, 30, 1024) 0           add_48[0][0]
__________________________________________________________________________________________________
res4b_branch2a (Conv2D)         (None, 30, 30, 256)  262400      activation_168[0][0]
__________________________________________________________________________________________________
bn4b_branch2a (BatchNormalizati (None, 30, 30, 256)  1024        res4b_branch2a[0][0]
__________________________________________________________________________________________________
activation_169 (Activation)     (None, 30, 30, 256)  0           bn4b_branch2a[0][0]
__________________________________________________________________________________________________
res4b_branch2b (Conv2D)         (None, 30, 30, 256)  590080      activation_169[0][0]
__________________________________________________________________________________________________
bn4b_branch2b (BatchNormalizati (None, 30, 30, 256)  1024        res4b_branch2b[0][0]
__________________________________________________________________________________________________
activation_170 (Activation)     (None, 30, 30, 256)  0           bn4b_branch2b[0][0]
__________________________________________________________________________________________________
res4b_branch2c (Conv2D)         (None, 30, 30, 1024) 263168      activation_170[0][0]
__________________________________________________________________________________________________
bn4b_branch2c (BatchNormalizati (None, 30, 30, 1024) 4096        res4b_branch2c[0][0]
__________________________________________________________________________________________________
add_49 (Add)                    (None, 30, 30, 1024) 0           bn4b_branch2c[0][0]
                                                                 activation_168[0][0]
__________________________________________________________________________________________________
activation_171 (Activation)     (None, 30, 30, 1024) 0           add_49[0][0]
__________________________________________________________________________________________________
res4c_branch2a (Conv2D)         (None, 30, 30, 256)  262400      activation_171[0][0]
__________________________________________________________________________________________________
bn4c_branch2a (BatchNormalizati (None, 30, 30, 256)  1024        res4c_branch2a[0][0]
__________________________________________________________________________________________________
activation_172 (Activation)     (None, 30, 30, 256)  0           bn4c_branch2a[0][0]
__________________________________________________________________________________________________
res4c_branch2b (Conv2D)         (None, 30, 30, 256)  590080      activation_172[0][0]
__________________________________________________________________________________________________
bn4c_branch2b (BatchNormalizati (None, 30, 30, 256)  1024        res4c_branch2b[0][0]
__________________________________________________________________________________________________
activation_173 (Activation)     (None, 30, 30, 256)  0           bn4c_branch2b[0][0]
__________________________________________________________________________________________________
res4c_branch2c (Conv2D)         (None, 30, 30, 1024) 263168      activation_173[0][0]
__________________________________________________________________________________________________
bn4c_branch2c (BatchNormalizati (None, 30, 30, 1024) 4096        res4c_branch2c[0][0]
__________________________________________________________________________________________________
add_50 (Add)                    (None, 30, 30, 1024) 0           bn4c_branch2c[0][0]
                                                                 activation_171[0][0]
__________________________________________________________________________________________________
activation_174 (Activation)     (None, 30, 30, 1024) 0           add_50[0][0]
__________________________________________________________________________________________________
res4d_branch2a (Conv2D)         (None, 30, 30, 256)  262400      activation_174[0][0]
__________________________________________________________________________________________________
bn4d_branch2a (BatchNormalizati (None, 30, 30, 256)  1024        res4d_branch2a[0][0]
__________________________________________________________________________________________________
activation_175 (Activation)     (None, 30, 30, 256)  0           bn4d_branch2a[0][0]
__________________________________________________________________________________________________
res4d_branch2b (Conv2D)         (None, 30, 30, 256)  590080      activation_175[0][0]
__________________________________________________________________________________________________
bn4d_branch2b (BatchNormalizati (None, 30, 30, 256)  1024        res4d_branch2b[0][0]
__________________________________________________________________________________________________
activation_176 (Activation)     (None, 30, 30, 256)  0           bn4d_branch2b[0][0]
__________________________________________________________________________________________________
res4d_branch2c (Conv2D)         (None, 30, 30, 1024) 263168      activation_176[0][0]
__________________________________________________________________________________________________
bn4d_branch2c (BatchNormalizati (None, 30, 30, 1024) 4096        res4d_branch2c[0][0]
__________________________________________________________________________________________________
add_51 (Add)                    (None, 30, 30, 1024) 0           bn4d_branch2c[0][0]
                                                                 activation_174[0][0]
__________________________________________________________________________________________________
activation_177 (Activation)     (None, 30, 30, 1024) 0           add_51[0][0]
__________________________________________________________________________________________________
res4e_branch2a (Conv2D)         (None, 30, 30, 256)  262400      activation_177[0][0]
__________________________________________________________________________________________________
bn4e_branch2a (BatchNormalizati (None, 30, 30, 256)  1024        res4e_branch2a[0][0]
__________________________________________________________________________________________________
activation_178 (Activation)     (None, 30, 30, 256)  0           bn4e_branch2a[0][0]
__________________________________________________________________________________________________
res4e_branch2b (Conv2D)         (None, 30, 30, 256)  590080      activation_178[0][0]
__________________________________________________________________________________________________
bn4e_branch2b (BatchNormalizati (None, 30, 30, 256)  1024        res4e_branch2b[0][0]
__________________________________________________________________________________________________
activation_179 (Activation)     (None, 30, 30, 256)  0           bn4e_branch2b[0][0]
__________________________________________________________________________________________________
res4e_branch2c (Conv2D)         (None, 30, 30, 1024) 263168      activation_179[0][0]
__________________________________________________________________________________________________
bn4e_branch2c (BatchNormalizati (None, 30, 30, 1024) 4096        res4e_branch2c[0][0]
__________________________________________________________________________________________________
add_52 (Add)                    (None, 30, 30, 1024) 0           bn4e_branch2c[0][0]
                                                                 activation_177[0][0]
__________________________________________________________________________________________________
activation_180 (Activation)     (None, 30, 30, 1024) 0           add_52[0][0]
__________________________________________________________________________________________________
res4f_branch2a (Conv2D)         (None, 30, 30, 256)  262400      activation_180[0][0]
__________________________________________________________________________________________________
bn4f_branch2a (BatchNormalizati (None, 30, 30, 256)  1024        res4f_branch2a[0][0]
__________________________________________________________________________________________________
activation_181 (Activation)     (None, 30, 30, 256)  0           bn4f_branch2a[0][0]
__________________________________________________________________________________________________
res4f_branch2b (Conv2D)         (None, 30, 30, 256)  590080      activation_181[0][0]
__________________________________________________________________________________________________
bn4f_branch2b (BatchNormalizati (None, 30, 30, 256)  1024        res4f_branch2b[0][0]
__________________________________________________________________________________________________
activation_182 (Activation)     (None, 30, 30, 256)  0           bn4f_branch2b[0][0]
__________________________________________________________________________________________________
res4f_branch2c (Conv2D)         (None, 30, 30, 1024) 263168      activation_182[0][0]
__________________________________________________________________________________________________
bn4f_branch2c (BatchNormalizati (None, 30, 30, 1024) 4096        res4f_branch2c[0][0]
__________________________________________________________________________________________________
add_53 (Add)                    (None, 30, 30, 1024) 0           bn4f_branch2c[0][0]
                                                                 activation_180[0][0]
__________________________________________________________________________________________________
activation_183 (Activation)     (None, 30, 30, 1024) 0           add_53[0][0]
__________________________________________________________________________________________________
res5a_branch2a (Conv2D)         (None, 15, 15, 512)  524800      activation_183[0][0]
__________________________________________________________________________________________________
bn5a_branch2a (BatchNormalizati (None, 15, 15, 512)  2048        res5a_branch2a[0][0]
__________________________________________________________________________________________________
activation_184 (Activation)     (None, 15, 15, 512)  0           bn5a_branch2a[0][0]
__________________________________________________________________________________________________
res5a_branch2b (Conv2D)         (None, 15, 15, 512)  2359808     activation_184[0][0]
__________________________________________________________________________________________________
bn5a_branch2b (BatchNormalizati (None, 15, 15, 512)  2048        res5a_branch2b[0][0]
__________________________________________________________________________________________________
activation_185 (Activation)     (None, 15, 15, 512)  0           bn5a_branch2b[0][0]
__________________________________________________________________________________________________
res5a_branch2c (Conv2D)         (None, 15, 15, 2048) 1050624     activation_185[0][0]
__________________________________________________________________________________________________
res5a_branch1 (Conv2D)          (None, 15, 15, 2048) 2099200     activation_183[0][0]
__________________________________________________________________________________________________
bn5a_branch2c (BatchNormalizati (None, 15, 15, 2048) 8192        res5a_branch2c[0][0]
__________________________________________________________________________________________________
bn5a_branch1 (BatchNormalizatio (None, 15, 15, 2048) 8192        res5a_branch1[0][0]
__________________________________________________________________________________________________
add_54 (Add)                    (None, 15, 15, 2048) 0           bn5a_branch2c[0][0]
                                                                 bn5a_branch1[0][0]
__________________________________________________________________________________________________
activation_186 (Activation)     (None, 15, 15, 2048) 0           add_54[0][0]
__________________________________________________________________________________________________
res5b_branch2a (Conv2D)         (None, 15, 15, 512)  1049088     activation_186[0][0]
__________________________________________________________________________________________________
bn5b_branch2a (BatchNormalizati (None, 15, 15, 512)  2048        res5b_branch2a[0][0]
__________________________________________________________________________________________________
activation_187 (Activation)     (None, 15, 15, 512)  0           bn5b_branch2a[0][0]
__________________________________________________________________________________________________
res5b_branch2b (Conv2D)         (None, 15, 15, 512)  2359808     activation_187[0][0]
__________________________________________________________________________________________________
bn5b_branch2b (BatchNormalizati (None, 15, 15, 512)  2048        res5b_branch2b[0][0]
__________________________________________________________________________________________________
activation_188 (Activation)     (None, 15, 15, 512)  0           bn5b_branch2b[0][0]
__________________________________________________________________________________________________
res5b_branch2c (Conv2D)         (None, 15, 15, 2048) 1050624     activation_188[0][0]
__________________________________________________________________________________________________
bn5b_branch2c (BatchNormalizati (None, 15, 15, 2048) 8192        res5b_branch2c[0][0]
__________________________________________________________________________________________________
add_55 (Add)                    (None, 15, 15, 2048) 0           bn5b_branch2c[0][0]
                                                                 activation_186[0][0]
__________________________________________________________________________________________________
activation_189 (Activation)     (None, 15, 15, 2048) 0           add_55[0][0]
__________________________________________________________________________________________________
res5c_branch2a (Conv2D)         (None, 15, 15, 512)  1049088     activation_189[0][0]
__________________________________________________________________________________________________
bn5c_branch2a (BatchNormalizati (None, 15, 15, 512)  2048        res5c_branch2a[0][0]
__________________________________________________________________________________________________
activation_190 (Activation)     (None, 15, 15, 512)  0           bn5c_branch2a[0][0]
__________________________________________________________________________________________________
res5c_branch2b (Conv2D)         (None, 15, 15, 512)  2359808     activation_190[0][0]
__________________________________________________________________________________________________
bn5c_branch2b (BatchNormalizati (None, 15, 15, 512)  2048        res5c_branch2b[0][0]
__________________________________________________________________________________________________
activation_191 (Activation)     (None, 15, 15, 512)  0           bn5c_branch2b[0][0]
__________________________________________________________________________________________________
res5c_branch2c (Conv2D)         (None, 15, 15, 2048) 1050624     activation_191[0][0]
__________________________________________________________________________________________________
bn5c_branch2c (BatchNormalizati (None, 15, 15, 2048) 8192        res5c_branch2c[0][0]
__________________________________________________________________________________________________
add_56 (Add)                    (None, 15, 15, 2048) 0           bn5c_branch2c[0][0]
                                                                 activation_189[0][0]
__________________________________________________________________________________________________
activation_192 (Activation)     (None, 15, 15, 2048) 0           add_56[0][0]
__________________________________________________________________________________________________
global_average_pooling2d_5 (Glo (None, 2048)         0           activation_192[0][0]
==================================================================================================
Total params: 23,587,712
Trainable params: 23,534,592
Non-trainable params: 53,120
__________________________________________________________________________________________________
257/257 [==============================] - 316s 1s/step
73/73 [==============================] - 91s 1s/step
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to
==================================================================================================
input_6 (InputLayer)            (None, 480, 480, 3)  0
__________________________________________________________________________________________________
lambda_12 (Lambda)              (None, 480, 480, 3)  0           input_6[0][0]
__________________________________________________________________________________________________
conv2d_103 (Conv2D)             (None, 239, 239, 32) 864         lambda_12[0][0]
__________________________________________________________________________________________________
batch_normalization_103 (BatchN (None, 239, 239, 32) 96          conv2d_103[0][0]
__________________________________________________________________________________________________
activation_193 (Activation)     (None, 239, 239, 32) 0           batch_normalization_103[0][0]
__________________________________________________________________________________________________
conv2d_104 (Conv2D)             (None, 237, 237, 32) 9216        activation_193[0][0]
__________________________________________________________________________________________________
batch_normalization_104 (BatchN (None, 237, 237, 32) 96          conv2d_104[0][0]
__________________________________________________________________________________________________
activation_194 (Activation)     (None, 237, 237, 32) 0           batch_normalization_104[0][0]
__________________________________________________________________________________________________
conv2d_105 (Conv2D)             (None, 237, 237, 64) 18432       activation_194[0][0]
__________________________________________________________________________________________________
batch_normalization_105 (BatchN (None, 237, 237, 64) 192         conv2d_105[0][0]
__________________________________________________________________________________________________
activation_195 (Activation)     (None, 237, 237, 64) 0           batch_normalization_105[0][0]
__________________________________________________________________________________________________
max_pooling2d_7 (MaxPooling2D)  (None, 118, 118, 64) 0           activation_195[0][0]
__________________________________________________________________________________________________
conv2d_106 (Conv2D)             (None, 118, 118, 80) 5120        max_pooling2d_7[0][0]
__________________________________________________________________________________________________
batch_normalization_106 (BatchN (None, 118, 118, 80) 240         conv2d_106[0][0]
__________________________________________________________________________________________________
activation_196 (Activation)     (None, 118, 118, 80) 0           batch_normalization_106[0][0]
__________________________________________________________________________________________________
conv2d_107 (Conv2D)             (None, 116, 116, 192 138240      activation_196[0][0]
__________________________________________________________________________________________________
batch_normalization_107 (BatchN (None, 116, 116, 192 576         conv2d_107[0][0]
__________________________________________________________________________________________________
activation_197 (Activation)     (None, 116, 116, 192 0           batch_normalization_107[0][0]
__________________________________________________________________________________________________
max_pooling2d_8 (MaxPooling2D)  (None, 57, 57, 192)  0           activation_197[0][0]
__________________________________________________________________________________________________
conv2d_111 (Conv2D)             (None, 57, 57, 64)   12288       max_pooling2d_8[0][0]
__________________________________________________________________________________________________
batch_normalization_111 (BatchN (None, 57, 57, 64)   192         conv2d_111[0][0]
__________________________________________________________________________________________________
activation_201 (Activation)     (None, 57, 57, 64)   0           batch_normalization_111[0][0]
__________________________________________________________________________________________________
conv2d_109 (Conv2D)             (None, 57, 57, 48)   9216        max_pooling2d_8[0][0]
__________________________________________________________________________________________________
conv2d_112 (Conv2D)             (None, 57, 57, 96)   55296       activation_201[0][0]
__________________________________________________________________________________________________
batch_normalization_109 (BatchN (None, 57, 57, 48)   144         conv2d_109[0][0]
__________________________________________________________________________________________________
batch_normalization_112 (BatchN (None, 57, 57, 96)   288         conv2d_112[0][0]
__________________________________________________________________________________________________
activation_199 (Activation)     (None, 57, 57, 48)   0           batch_normalization_109[0][0]
__________________________________________________________________________________________________
activation_202 (Activation)     (None, 57, 57, 96)   0           batch_normalization_112[0][0]
__________________________________________________________________________________________________
average_pooling2d_10 (AveragePo (None, 57, 57, 192)  0           max_pooling2d_8[0][0]
__________________________________________________________________________________________________
conv2d_108 (Conv2D)             (None, 57, 57, 64)   12288       max_pooling2d_8[0][0]
__________________________________________________________________________________________________
conv2d_110 (Conv2D)             (None, 57, 57, 64)   76800       activation_199[0][0]
__________________________________________________________________________________________________
conv2d_113 (Conv2D)             (None, 57, 57, 96)   82944       activation_202[0][0]
__________________________________________________________________________________________________
conv2d_114 (Conv2D)             (None, 57, 57, 32)   6144        average_pooling2d_10[0][0]
__________________________________________________________________________________________________
batch_normalization_108 (BatchN (None, 57, 57, 64)   192         conv2d_108[0][0]
__________________________________________________________________________________________________
batch_normalization_110 (BatchN (None, 57, 57, 64)   192         conv2d_110[0][0]
__________________________________________________________________________________________________
batch_normalization_113 (BatchN (None, 57, 57, 96)   288         conv2d_113[0][0]
__________________________________________________________________________________________________
batch_normalization_114 (BatchN (None, 57, 57, 32)   96          conv2d_114[0][0]
__________________________________________________________________________________________________
activation_198 (Activation)     (None, 57, 57, 64)   0           batch_normalization_108[0][0]
__________________________________________________________________________________________________
activation_200 (Activation)     (None, 57, 57, 64)   0           batch_normalization_110[0][0]
__________________________________________________________________________________________________
activation_203 (Activation)     (None, 57, 57, 96)   0           batch_normalization_113[0][0]
__________________________________________________________________________________________________
activation_204 (Activation)     (None, 57, 57, 32)   0           batch_normalization_114[0][0]
__________________________________________________________________________________________________
mixed0 (Concatenate)            (None, 57, 57, 256)  0           activation_198[0][0]
                                                                 activation_200[0][0]
                                                                 activation_203[0][0]
                                                                 activation_204[0][0]
__________________________________________________________________________________________________
conv2d_118 (Conv2D)             (None, 57, 57, 64)   16384       mixed0[0][0]
__________________________________________________________________________________________________
batch_normalization_118 (BatchN (None, 57, 57, 64)   192         conv2d_118[0][0]
__________________________________________________________________________________________________
activation_208 (Activation)     (None, 57, 57, 64)   0           batch_normalization_118[0][0]
__________________________________________________________________________________________________
conv2d_116 (Conv2D)             (None, 57, 57, 48)   12288       mixed0[0][0]
__________________________________________________________________________________________________
conv2d_119 (Conv2D)             (None, 57, 57, 96)   55296       activation_208[0][0]
__________________________________________________________________________________________________
batch_normalization_116 (BatchN (None, 57, 57, 48)   144         conv2d_116[0][0]
__________________________________________________________________________________________________
batch_normalization_119 (BatchN (None, 57, 57, 96)   288         conv2d_119[0][0]
__________________________________________________________________________________________________
activation_206 (Activation)     (None, 57, 57, 48)   0           batch_normalization_116[0][0]
__________________________________________________________________________________________________
activation_209 (Activation)     (None, 57, 57, 96)   0           batch_normalization_119[0][0]
__________________________________________________________________________________________________
average_pooling2d_11 (AveragePo (None, 57, 57, 256)  0           mixed0[0][0]
__________________________________________________________________________________________________
conv2d_115 (Conv2D)             (None, 57, 57, 64)   16384       mixed0[0][0]
__________________________________________________________________________________________________
conv2d_117 (Conv2D)             (None, 57, 57, 64)   76800       activation_206[0][0]
__________________________________________________________________________________________________
conv2d_120 (Conv2D)             (None, 57, 57, 96)   82944       activation_209[0][0]
__________________________________________________________________________________________________
conv2d_121 (Conv2D)             (None, 57, 57, 64)   16384       average_pooling2d_11[0][0]
__________________________________________________________________________________________________
batch_normalization_115 (BatchN (None, 57, 57, 64)   192         conv2d_115[0][0]
__________________________________________________________________________________________________
batch_normalization_117 (BatchN (None, 57, 57, 64)   192         conv2d_117[0][0]
__________________________________________________________________________________________________
batch_normalization_120 (BatchN (None, 57, 57, 96)   288         conv2d_120[0][0]
__________________________________________________________________________________________________
batch_normalization_121 (BatchN (None, 57, 57, 64)   192         conv2d_121[0][0]
__________________________________________________________________________________________________
activation_205 (Activation)     (None, 57, 57, 64)   0           batch_normalization_115[0][0]
__________________________________________________________________________________________________
activation_207 (Activation)     (None, 57, 57, 64)   0           batch_normalization_117[0][0]
__________________________________________________________________________________________________
activation_210 (Activation)     (None, 57, 57, 96)   0           batch_normalization_120[0][0]
__________________________________________________________________________________________________
activation_211 (Activation)     (None, 57, 57, 64)   0           batch_normalization_121[0][0]
__________________________________________________________________________________________________
mixed1 (Concatenate)            (None, 57, 57, 288)  0           activation_205[0][0]
                                                                 activation_207[0][0]
                                                                 activation_210[0][0]
                                                                 activation_211[0][0]
__________________________________________________________________________________________________
conv2d_125 (Conv2D)             (None, 57, 57, 64)   18432       mixed1[0][0]
__________________________________________________________________________________________________
batch_normalization_125 (BatchN (None, 57, 57, 64)   192         conv2d_125[0][0]
__________________________________________________________________________________________________
activation_215 (Activation)     (None, 57, 57, 64)   0           batch_normalization_125[0][0]
__________________________________________________________________________________________________
conv2d_123 (Conv2D)             (None, 57, 57, 48)   13824       mixed1[0][0]
__________________________________________________________________________________________________
conv2d_126 (Conv2D)             (None, 57, 57, 96)   55296       activation_215[0][0]
__________________________________________________________________________________________________
batch_normalization_123 (BatchN (None, 57, 57, 48)   144         conv2d_123[0][0]
__________________________________________________________________________________________________
batch_normalization_126 (BatchN (None, 57, 57, 96)   288         conv2d_126[0][0]
__________________________________________________________________________________________________
activation_213 (Activation)     (None, 57, 57, 48)   0           batch_normalization_123[0][0]
__________________________________________________________________________________________________
activation_216 (Activation)     (None, 57, 57, 96)   0           batch_normalization_126[0][0]
__________________________________________________________________________________________________
average_pooling2d_12 (AveragePo (None, 57, 57, 288)  0           mixed1[0][0]
__________________________________________________________________________________________________
conv2d_122 (Conv2D)             (None, 57, 57, 64)   18432       mixed1[0][0]
__________________________________________________________________________________________________
conv2d_124 (Conv2D)             (None, 57, 57, 64)   76800       activation_213[0][0]
__________________________________________________________________________________________________
conv2d_127 (Conv2D)             (None, 57, 57, 96)   82944       activation_216[0][0]
__________________________________________________________________________________________________
conv2d_128 (Conv2D)             (None, 57, 57, 64)   18432       average_pooling2d_12[0][0]
__________________________________________________________________________________________________
batch_normalization_122 (BatchN (None, 57, 57, 64)   192         conv2d_122[0][0]
__________________________________________________________________________________________________
batch_normalization_124 (BatchN (None, 57, 57, 64)   192         conv2d_124[0][0]
__________________________________________________________________________________________________
batch_normalization_127 (BatchN (None, 57, 57, 96)   288         conv2d_127[0][0]
__________________________________________________________________________________________________
batch_normalization_128 (BatchN (None, 57, 57, 64)   192         conv2d_128[0][0]
__________________________________________________________________________________________________
activation_212 (Activation)     (None, 57, 57, 64)   0           batch_normalization_122[0][0]
__________________________________________________________________________________________________
activation_214 (Activation)     (None, 57, 57, 64)   0           batch_normalization_124[0][0]
__________________________________________________________________________________________________
activation_217 (Activation)     (None, 57, 57, 96)   0           batch_normalization_127[0][0]
__________________________________________________________________________________________________
activation_218 (Activation)     (None, 57, 57, 64)   0           batch_normalization_128[0][0]
__________________________________________________________________________________________________
mixed2 (Concatenate)            (None, 57, 57, 288)  0           activation_212[0][0]
                                                                 activation_214[0][0]
                                                                 activation_217[0][0]
                                                                 activation_218[0][0]
__________________________________________________________________________________________________
conv2d_130 (Conv2D)             (None, 57, 57, 64)   18432       mixed2[0][0]
__________________________________________________________________________________________________
batch_normalization_130 (BatchN (None, 57, 57, 64)   192         conv2d_130[0][0]
__________________________________________________________________________________________________
activation_220 (Activation)     (None, 57, 57, 64)   0           batch_normalization_130[0][0]
__________________________________________________________________________________________________
conv2d_131 (Conv2D)             (None, 57, 57, 96)   55296       activation_220[0][0]
__________________________________________________________________________________________________
batch_normalization_131 (BatchN (None, 57, 57, 96)   288         conv2d_131[0][0]
__________________________________________________________________________________________________
activation_221 (Activation)     (None, 57, 57, 96)   0           batch_normalization_131[0][0]
__________________________________________________________________________________________________
conv2d_129 (Conv2D)             (None, 28, 28, 384)  995328      mixed2[0][0]
__________________________________________________________________________________________________
conv2d_132 (Conv2D)             (None, 28, 28, 96)   82944       activation_221[0][0]
__________________________________________________________________________________________________
batch_normalization_129 (BatchN (None, 28, 28, 384)  1152        conv2d_129[0][0]
__________________________________________________________________________________________________
batch_normalization_132 (BatchN (None, 28, 28, 96)   288         conv2d_132[0][0]
__________________________________________________________________________________________________
activation_219 (Activation)     (None, 28, 28, 384)  0           batch_normalization_129[0][0]
__________________________________________________________________________________________________
activation_222 (Activation)     (None, 28, 28, 96)   0           batch_normalization_132[0][0]
__________________________________________________________________________________________________
max_pooling2d_9 (MaxPooling2D)  (None, 28, 28, 288)  0           mixed2[0][0]
__________________________________________________________________________________________________
mixed3 (Concatenate)            (None, 28, 28, 768)  0           activation_219[0][0]
                                                                 activation_222[0][0]
                                                                 max_pooling2d_9[0][0]
__________________________________________________________________________________________________
conv2d_137 (Conv2D)             (None, 28, 28, 128)  98304       mixed3[0][0]
__________________________________________________________________________________________________
batch_normalization_137 (BatchN (None, 28, 28, 128)  384         conv2d_137[0][0]
__________________________________________________________________________________________________
activation_227 (Activation)     (None, 28, 28, 128)  0           batch_normalization_137[0][0]
__________________________________________________________________________________________________
conv2d_138 (Conv2D)             (None, 28, 28, 128)  114688      activation_227[0][0]
__________________________________________________________________________________________________
batch_normalization_138 (BatchN (None, 28, 28, 128)  384         conv2d_138[0][0]
__________________________________________________________________________________________________
activation_228 (Activation)     (None, 28, 28, 128)  0           batch_normalization_138[0][0]
__________________________________________________________________________________________________
conv2d_134 (Conv2D)             (None, 28, 28, 128)  98304       mixed3[0][0]
__________________________________________________________________________________________________
conv2d_139 (Conv2D)             (None, 28, 28, 128)  114688      activation_228[0][0]
__________________________________________________________________________________________________
batch_normalization_134 (BatchN (None, 28, 28, 128)  384         conv2d_134[0][0]
__________________________________________________________________________________________________
batch_normalization_139 (BatchN (None, 28, 28, 128)  384         conv2d_139[0][0]
__________________________________________________________________________________________________
activation_224 (Activation)     (None, 28, 28, 128)  0           batch_normalization_134[0][0]
__________________________________________________________________________________________________
activation_229 (Activation)     (None, 28, 28, 128)  0           batch_normalization_139[0][0]
__________________________________________________________________________________________________
conv2d_135 (Conv2D)             (None, 28, 28, 128)  114688      activation_224[0][0]
__________________________________________________________________________________________________
conv2d_140 (Conv2D)             (None, 28, 28, 128)  114688      activation_229[0][0]
__________________________________________________________________________________________________
batch_normalization_135 (BatchN (None, 28, 28, 128)  384         conv2d_135[0][0]
__________________________________________________________________________________________________
batch_normalization_140 (BatchN (None, 28, 28, 128)  384         conv2d_140[0][0]
__________________________________________________________________________________________________
activation_225 (Activation)     (None, 28, 28, 128)  0           batch_normalization_135[0][0]
__________________________________________________________________________________________________
activation_230 (Activation)     (None, 28, 28, 128)  0           batch_normalization_140[0][0]
__________________________________________________________________________________________________
average_pooling2d_13 (AveragePo (None, 28, 28, 768)  0           mixed3[0][0]
__________________________________________________________________________________________________
conv2d_133 (Conv2D)             (None, 28, 28, 192)  147456      mixed3[0][0]
__________________________________________________________________________________________________
conv2d_136 (Conv2D)             (None, 28, 28, 192)  172032      activation_225[0][0]
__________________________________________________________________________________________________
conv2d_141 (Conv2D)             (None, 28, 28, 192)  172032      activation_230[0][0]
__________________________________________________________________________________________________
conv2d_142 (Conv2D)             (None, 28, 28, 192)  147456      average_pooling2d_13[0][0]
__________________________________________________________________________________________________
batch_normalization_133 (BatchN (None, 28, 28, 192)  576         conv2d_133[0][0]
__________________________________________________________________________________________________
batch_normalization_136 (BatchN (None, 28, 28, 192)  576         conv2d_136[0][0]
__________________________________________________________________________________________________
batch_normalization_141 (BatchN (None, 28, 28, 192)  576         conv2d_141[0][0]
__________________________________________________________________________________________________
batch_normalization_142 (BatchN (None, 28, 28, 192)  576         conv2d_142[0][0]
__________________________________________________________________________________________________
activation_223 (Activation)     (None, 28, 28, 192)  0           batch_normalization_133[0][0]
__________________________________________________________________________________________________
activation_226 (Activation)     (None, 28, 28, 192)  0           batch_normalization_136[0][0]
__________________________________________________________________________________________________
activation_231 (Activation)     (None, 28, 28, 192)  0           batch_normalization_141[0][0]
__________________________________________________________________________________________________
activation_232 (Activation)     (None, 28, 28, 192)  0           batch_normalization_142[0][0]
__________________________________________________________________________________________________
mixed4 (Concatenate)            (None, 28, 28, 768)  0           activation_223[0][0]
                                                                 activation_226[0][0]
                                                                 activation_231[0][0]
                                                                 activation_232[0][0]
__________________________________________________________________________________________________
conv2d_147 (Conv2D)             (None, 28, 28, 160)  122880      mixed4[0][0]
__________________________________________________________________________________________________
batch_normalization_147 (BatchN (None, 28, 28, 160)  480         conv2d_147[0][0]
__________________________________________________________________________________________________
activation_237 (Activation)     (None, 28, 28, 160)  0           batch_normalization_147[0][0]
__________________________________________________________________________________________________
conv2d_148 (Conv2D)             (None, 28, 28, 160)  179200      activation_237[0][0]
__________________________________________________________________________________________________
batch_normalization_148 (BatchN (None, 28, 28, 160)  480         conv2d_148[0][0]
__________________________________________________________________________________________________
activation_238 (Activation)     (None, 28, 28, 160)  0           batch_normalization_148[0][0]
__________________________________________________________________________________________________
conv2d_144 (Conv2D)             (None, 28, 28, 160)  122880      mixed4[0][0]
__________________________________________________________________________________________________
conv2d_149 (Conv2D)             (None, 28, 28, 160)  179200      activation_238[0][0]
__________________________________________________________________________________________________
batch_normalization_144 (BatchN (None, 28, 28, 160)  480         conv2d_144[0][0]
__________________________________________________________________________________________________
batch_normalization_149 (BatchN (None, 28, 28, 160)  480         conv2d_149[0][0]
__________________________________________________________________________________________________
activation_234 (Activation)     (None, 28, 28, 160)  0           batch_normalization_144[0][0]
__________________________________________________________________________________________________
activation_239 (Activation)     (None, 28, 28, 160)  0           batch_normalization_149[0][0]
__________________________________________________________________________________________________
conv2d_145 (Conv2D)             (None, 28, 28, 160)  179200      activation_234[0][0]
__________________________________________________________________________________________________
conv2d_150 (Conv2D)             (None, 28, 28, 160)  179200      activation_239[0][0]
__________________________________________________________________________________________________
batch_normalization_145 (BatchN (None, 28, 28, 160)  480         conv2d_145[0][0]
__________________________________________________________________________________________________
batch_normalization_150 (BatchN (None, 28, 28, 160)  480         conv2d_150[0][0]
__________________________________________________________________________________________________
activation_235 (Activation)     (None, 28, 28, 160)  0           batch_normalization_145[0][0]
__________________________________________________________________________________________________
activation_240 (Activation)     (None, 28, 28, 160)  0           batch_normalization_150[0][0]
__________________________________________________________________________________________________
average_pooling2d_14 (AveragePo (None, 28, 28, 768)  0           mixed4[0][0]
__________________________________________________________________________________________________
conv2d_143 (Conv2D)             (None, 28, 28, 192)  147456      mixed4[0][0]
__________________________________________________________________________________________________
conv2d_146 (Conv2D)             (None, 28, 28, 192)  215040      activation_235[0][0]
__________________________________________________________________________________________________
conv2d_151 (Conv2D)             (None, 28, 28, 192)  215040      activation_240[0][0]
__________________________________________________________________________________________________
conv2d_152 (Conv2D)             (None, 28, 28, 192)  147456      average_pooling2d_14[0][0]
__________________________________________________________________________________________________
batch_normalization_143 (BatchN (None, 28, 28, 192)  576         conv2d_143[0][0]
__________________________________________________________________________________________________
batch_normalization_146 (BatchN (None, 28, 28, 192)  576         conv2d_146[0][0]
__________________________________________________________________________________________________
batch_normalization_151 (BatchN (None, 28, 28, 192)  576         conv2d_151[0][0]
__________________________________________________________________________________________________
batch_normalization_152 (BatchN (None, 28, 28, 192)  576         conv2d_152[0][0]
__________________________________________________________________________________________________
activation_233 (Activation)     (None, 28, 28, 192)  0           batch_normalization_143[0][0]
__________________________________________________________________________________________________
activation_236 (Activation)     (None, 28, 28, 192)  0           batch_normalization_146[0][0]
__________________________________________________________________________________________________
activation_241 (Activation)     (None, 28, 28, 192)  0           batch_normalization_151[0][0]
__________________________________________________________________________________________________
activation_242 (Activation)     (None, 28, 28, 192)  0           batch_normalization_152[0][0]
__________________________________________________________________________________________________
mixed5 (Concatenate)            (None, 28, 28, 768)  0           activation_233[0][0]
                                                                 activation_236[0][0]
                                                                 activation_241[0][0]
                                                                 activation_242[0][0]
__________________________________________________________________________________________________
conv2d_157 (Conv2D)             (None, 28, 28, 160)  122880      mixed5[0][0]
__________________________________________________________________________________________________
batch_normalization_157 (BatchN (None, 28, 28, 160)  480         conv2d_157[0][0]
__________________________________________________________________________________________________
activation_247 (Activation)     (None, 28, 28, 160)  0           batch_normalization_157[0][0]
__________________________________________________________________________________________________
conv2d_158 (Conv2D)             (None, 28, 28, 160)  179200      activation_247[0][0]
__________________________________________________________________________________________________
batch_normalization_158 (BatchN (None, 28, 28, 160)  480         conv2d_158[0][0]
__________________________________________________________________________________________________
activation_248 (Activation)     (None, 28, 28, 160)  0           batch_normalization_158[0][0]
__________________________________________________________________________________________________
conv2d_154 (Conv2D)             (None, 28, 28, 160)  122880      mixed5[0][0]
__________________________________________________________________________________________________
conv2d_159 (Conv2D)             (None, 28, 28, 160)  179200      activation_248[0][0]
__________________________________________________________________________________________________
batch_normalization_154 (BatchN (None, 28, 28, 160)  480         conv2d_154[0][0]
__________________________________________________________________________________________________
batch_normalization_159 (BatchN (None, 28, 28, 160)  480         conv2d_159[0][0]
__________________________________________________________________________________________________
activation_244 (Activation)     (None, 28, 28, 160)  0           batch_normalization_154[0][0]
__________________________________________________________________________________________________
activation_249 (Activation)     (None, 28, 28, 160)  0           batch_normalization_159[0][0]
__________________________________________________________________________________________________
conv2d_155 (Conv2D)             (None, 28, 28, 160)  179200      activation_244[0][0]
__________________________________________________________________________________________________
conv2d_160 (Conv2D)             (None, 28, 28, 160)  179200      activation_249[0][0]
__________________________________________________________________________________________________
batch_normalization_155 (BatchN (None, 28, 28, 160)  480         conv2d_155[0][0]
__________________________________________________________________________________________________
batch_normalization_160 (BatchN (None, 28, 28, 160)  480         conv2d_160[0][0]
__________________________________________________________________________________________________
activation_245 (Activation)     (None, 28, 28, 160)  0           batch_normalization_155[0][0]
__________________________________________________________________________________________________
activation_250 (Activation)     (None, 28, 28, 160)  0           batch_normalization_160[0][0]
__________________________________________________________________________________________________
average_pooling2d_15 (AveragePo (None, 28, 28, 768)  0           mixed5[0][0]
__________________________________________________________________________________________________
conv2d_153 (Conv2D)             (None, 28, 28, 192)  147456      mixed5[0][0]
__________________________________________________________________________________________________
conv2d_156 (Conv2D)             (None, 28, 28, 192)  215040      activation_245[0][0]
__________________________________________________________________________________________________
conv2d_161 (Conv2D)             (None, 28, 28, 192)  215040      activation_250[0][0]
__________________________________________________________________________________________________
conv2d_162 (Conv2D)             (None, 28, 28, 192)  147456      average_pooling2d_15[0][0]
__________________________________________________________________________________________________
batch_normalization_153 (BatchN (None, 28, 28, 192)  576         conv2d_153[0][0]
__________________________________________________________________________________________________
batch_normalization_156 (BatchN (None, 28, 28, 192)  576         conv2d_156[0][0]
__________________________________________________________________________________________________
batch_normalization_161 (BatchN (None, 28, 28, 192)  576         conv2d_161[0][0]
__________________________________________________________________________________________________
batch_normalization_162 (BatchN (None, 28, 28, 192)  576         conv2d_162[0][0]
__________________________________________________________________________________________________
activation_243 (Activation)     (None, 28, 28, 192)  0           batch_normalization_153[0][0]
__________________________________________________________________________________________________
activation_246 (Activation)     (None, 28, 28, 192)  0           batch_normalization_156[0][0]
__________________________________________________________________________________________________
activation_251 (Activation)     (None, 28, 28, 192)  0           batch_normalization_161[0][0]
__________________________________________________________________________________________________
activation_252 (Activation)     (None, 28, 28, 192)  0           batch_normalization_162[0][0]
__________________________________________________________________________________________________
mixed6 (Concatenate)            (None, 28, 28, 768)  0           activation_243[0][0]
                                                                 activation_246[0][0]
                                                                 activation_251[0][0]
                                                                 activation_252[0][0]
__________________________________________________________________________________________________
conv2d_167 (Conv2D)             (None, 28, 28, 192)  147456      mixed6[0][0]
__________________________________________________________________________________________________
batch_normalization_167 (BatchN (None, 28, 28, 192)  576         conv2d_167[0][0]
__________________________________________________________________________________________________
activation_257 (Activation)     (None, 28, 28, 192)  0           batch_normalization_167[0][0]
__________________________________________________________________________________________________
conv2d_168 (Conv2D)             (None, 28, 28, 192)  258048      activation_257[0][0]
__________________________________________________________________________________________________
batch_normalization_168 (BatchN (None, 28, 28, 192)  576         conv2d_168[0][0]
__________________________________________________________________________________________________
activation_258 (Activation)     (None, 28, 28, 192)  0           batch_normalization_168[0][0]
__________________________________________________________________________________________________
conv2d_164 (Conv2D)             (None, 28, 28, 192)  147456      mixed6[0][0]
__________________________________________________________________________________________________
conv2d_169 (Conv2D)             (None, 28, 28, 192)  258048      activation_258[0][0]
__________________________________________________________________________________________________
batch_normalization_164 (BatchN (None, 28, 28, 192)  576         conv2d_164[0][0]
__________________________________________________________________________________________________
batch_normalization_169 (BatchN (None, 28, 28, 192)  576         conv2d_169[0][0]
__________________________________________________________________________________________________
activation_254 (Activation)     (None, 28, 28, 192)  0           batch_normalization_164[0][0]
__________________________________________________________________________________________________
activation_259 (Activation)     (None, 28, 28, 192)  0           batch_normalization_169[0][0]
__________________________________________________________________________________________________
conv2d_165 (Conv2D)             (None, 28, 28, 192)  258048      activation_254[0][0]
__________________________________________________________________________________________________
conv2d_170 (Conv2D)             (None, 28, 28, 192)  258048      activation_259[0][0]
__________________________________________________________________________________________________
batch_normalization_165 (BatchN (None, 28, 28, 192)  576         conv2d_165[0][0]
__________________________________________________________________________________________________
batch_normalization_170 (BatchN (None, 28, 28, 192)  576         conv2d_170[0][0]
__________________________________________________________________________________________________
activation_255 (Activation)     (None, 28, 28, 192)  0           batch_normalization_165[0][0]
__________________________________________________________________________________________________
activation_260 (Activation)     (None, 28, 28, 192)  0           batch_normalization_170[0][0]
__________________________________________________________________________________________________
average_pooling2d_16 (AveragePo (None, 28, 28, 768)  0           mixed6[0][0]
__________________________________________________________________________________________________
conv2d_163 (Conv2D)             (None, 28, 28, 192)  147456      mixed6[0][0]
__________________________________________________________________________________________________
conv2d_166 (Conv2D)             (None, 28, 28, 192)  258048      activation_255[0][0]
__________________________________________________________________________________________________
conv2d_171 (Conv2D)             (None, 28, 28, 192)  258048      activation_260[0][0]
__________________________________________________________________________________________________
conv2d_172 (Conv2D)             (None, 28, 28, 192)  147456      average_pooling2d_16[0][0]
__________________________________________________________________________________________________
batch_normalization_163 (BatchN (None, 28, 28, 192)  576         conv2d_163[0][0]
__________________________________________________________________________________________________
batch_normalization_166 (BatchN (None, 28, 28, 192)  576         conv2d_166[0][0]
__________________________________________________________________________________________________
batch_normalization_171 (BatchN (None, 28, 28, 192)  576         conv2d_171[0][0]
__________________________________________________________________________________________________
batch_normalization_172 (BatchN (None, 28, 28, 192)  576         conv2d_172[0][0]
__________________________________________________________________________________________________
activation_253 (Activation)     (None, 28, 28, 192)  0           batch_normalization_163[0][0]
__________________________________________________________________________________________________
activation_256 (Activation)     (None, 28, 28, 192)  0           batch_normalization_166[0][0]
__________________________________________________________________________________________________
activation_261 (Activation)     (None, 28, 28, 192)  0           batch_normalization_171[0][0]
__________________________________________________________________________________________________
activation_262 (Activation)     (None, 28, 28, 192)  0           batch_normalization_172[0][0]
__________________________________________________________________________________________________
mixed7 (Concatenate)            (None, 28, 28, 768)  0           activation_253[0][0]
                                                                 activation_256[0][0]
                                                                 activation_261[0][0]
                                                                 activation_262[0][0]
__________________________________________________________________________________________________
conv2d_175 (Conv2D)             (None, 28, 28, 192)  147456      mixed7[0][0]
__________________________________________________________________________________________________
batch_normalization_175 (BatchN (None, 28, 28, 192)  576         conv2d_175[0][0]
__________________________________________________________________________________________________
activation_265 (Activation)     (None, 28, 28, 192)  0           batch_normalization_175[0][0]
__________________________________________________________________________________________________
conv2d_176 (Conv2D)             (None, 28, 28, 192)  258048      activation_265[0][0]
__________________________________________________________________________________________________
batch_normalization_176 (BatchN (None, 28, 28, 192)  576         conv2d_176[0][0]
__________________________________________________________________________________________________
activation_266 (Activation)     (None, 28, 28, 192)  0           batch_normalization_176[0][0]
__________________________________________________________________________________________________
conv2d_173 (Conv2D)             (None, 28, 28, 192)  147456      mixed7[0][0]
__________________________________________________________________________________________________
conv2d_177 (Conv2D)             (None, 28, 28, 192)  258048      activation_266[0][0]
__________________________________________________________________________________________________
batch_normalization_173 (BatchN (None, 28, 28, 192)  576         conv2d_173[0][0]
__________________________________________________________________________________________________
batch_normalization_177 (BatchN (None, 28, 28, 192)  576         conv2d_177[0][0]
__________________________________________________________________________________________________
activation_263 (Activation)     (None, 28, 28, 192)  0           batch_normalization_173[0][0]
__________________________________________________________________________________________________
activation_267 (Activation)     (None, 28, 28, 192)  0           batch_normalization_177[0][0]
__________________________________________________________________________________________________
conv2d_174 (Conv2D)             (None, 13, 13, 320)  552960      activation_263[0][0]
__________________________________________________________________________________________________
conv2d_178 (Conv2D)             (None, 13, 13, 192)  331776      activation_267[0][0]
__________________________________________________________________________________________________
batch_normalization_174 (BatchN (None, 13, 13, 320)  960         conv2d_174[0][0]
__________________________________________________________________________________________________
batch_normalization_178 (BatchN (None, 13, 13, 192)  576         conv2d_178[0][0]
__________________________________________________________________________________________________
activation_264 (Activation)     (None, 13, 13, 320)  0           batch_normalization_174[0][0]
__________________________________________________________________________________________________
activation_268 (Activation)     (None, 13, 13, 192)  0           batch_normalization_178[0][0]
__________________________________________________________________________________________________
max_pooling2d_10 (MaxPooling2D) (None, 13, 13, 768)  0           mixed7[0][0]
__________________________________________________________________________________________________
mixed8 (Concatenate)            (None, 13, 13, 1280) 0           activation_264[0][0]
                                                                 activation_268[0][0]
                                                                 max_pooling2d_10[0][0]
__________________________________________________________________________________________________
conv2d_183 (Conv2D)             (None, 13, 13, 448)  573440      mixed8[0][0]
__________________________________________________________________________________________________
batch_normalization_183 (BatchN (None, 13, 13, 448)  1344        conv2d_183[0][0]
__________________________________________________________________________________________________
activation_273 (Activation)     (None, 13, 13, 448)  0           batch_normalization_183[0][0]
__________________________________________________________________________________________________
conv2d_180 (Conv2D)             (None, 13, 13, 384)  491520      mixed8[0][0]
__________________________________________________________________________________________________
conv2d_184 (Conv2D)             (None, 13, 13, 384)  1548288     activation_273[0][0]
__________________________________________________________________________________________________
batch_normalization_180 (BatchN (None, 13, 13, 384)  1152        conv2d_180[0][0]
__________________________________________________________________________________________________
batch_normalization_184 (BatchN (None, 13, 13, 384)  1152        conv2d_184[0][0]
__________________________________________________________________________________________________
activation_270 (Activation)     (None, 13, 13, 384)  0           batch_normalization_180[0][0]
__________________________________________________________________________________________________
activation_274 (Activation)     (None, 13, 13, 384)  0           batch_normalization_184[0][0]
__________________________________________________________________________________________________
conv2d_181 (Conv2D)             (None, 13, 13, 384)  442368      activation_270[0][0]
__________________________________________________________________________________________________
conv2d_182 (Conv2D)             (None, 13, 13, 384)  442368      activation_270[0][0]
__________________________________________________________________________________________________
conv2d_185 (Conv2D)             (None, 13, 13, 384)  442368      activation_274[0][0]
__________________________________________________________________________________________________
conv2d_186 (Conv2D)             (None, 13, 13, 384)  442368      activation_274[0][0]
__________________________________________________________________________________________________
average_pooling2d_17 (AveragePo (None, 13, 13, 1280) 0           mixed8[0][0]
__________________________________________________________________________________________________
conv2d_179 (Conv2D)             (None, 13, 13, 320)  409600      mixed8[0][0]
__________________________________________________________________________________________________
batch_normalization_181 (BatchN (None, 13, 13, 384)  1152        conv2d_181[0][0]
__________________________________________________________________________________________________
batch_normalization_182 (BatchN (None, 13, 13, 384)  1152        conv2d_182[0][0]
__________________________________________________________________________________________________
batch_normalization_185 (BatchN (None, 13, 13, 384)  1152        conv2d_185[0][0]
__________________________________________________________________________________________________
batch_normalization_186 (BatchN (None, 13, 13, 384)  1152        conv2d_186[0][0]
__________________________________________________________________________________________________
conv2d_187 (Conv2D)             (None, 13, 13, 192)  245760      average_pooling2d_17[0][0]
__________________________________________________________________________________________________
batch_normalization_179 (BatchN (None, 13, 13, 320)  960         conv2d_179[0][0]
__________________________________________________________________________________________________
activation_271 (Activation)     (None, 13, 13, 384)  0           batch_normalization_181[0][0]
__________________________________________________________________________________________________
activation_272 (Activation)     (None, 13, 13, 384)  0           batch_normalization_182[0][0]
__________________________________________________________________________________________________
activation_275 (Activation)     (None, 13, 13, 384)  0           batch_normalization_185[0][0]
__________________________________________________________________________________________________
activation_276 (Activation)     (None, 13, 13, 384)  0           batch_normalization_186[0][0]
__________________________________________________________________________________________________
batch_normalization_187 (BatchN (None, 13, 13, 192)  576         conv2d_187[0][0]
__________________________________________________________________________________________________
activation_269 (Activation)     (None, 13, 13, 320)  0           batch_normalization_179[0][0]
__________________________________________________________________________________________________
mixed9_0 (Concatenate)          (None, 13, 13, 768)  0           activation_271[0][0]
                                                                 activation_272[0][0]
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 13, 768)  0           activation_275[0][0]
                                                                 activation_276[0][0]
__________________________________________________________________________________________________
activation_277 (Activation)     (None, 13, 13, 192)  0           batch_normalization_187[0][0]
__________________________________________________________________________________________________
mixed9 (Concatenate)            (None, 13, 13, 2048) 0           activation_269[0][0]
                                                                 mixed9_0[0][0]
                                                                 concatenate_3[0][0]
                                                                 activation_277[0][0]
__________________________________________________________________________________________________
conv2d_192 (Conv2D)             (None, 13, 13, 448)  917504      mixed9[0][0]
__________________________________________________________________________________________________
batch_normalization_192 (BatchN (None, 13, 13, 448)  1344        conv2d_192[0][0]
__________________________________________________________________________________________________
activation_282 (Activation)     (None, 13, 13, 448)  0           batch_normalization_192[0][0]
__________________________________________________________________________________________________
conv2d_189 (Conv2D)             (None, 13, 13, 384)  786432      mixed9[0][0]
__________________________________________________________________________________________________
conv2d_193 (Conv2D)             (None, 13, 13, 384)  1548288     activation_282[0][0]
__________________________________________________________________________________________________
batch_normalization_189 (BatchN (None, 13, 13, 384)  1152        conv2d_189[0][0]
__________________________________________________________________________________________________
batch_normalization_193 (BatchN (None, 13, 13, 384)  1152        conv2d_193[0][0]
__________________________________________________________________________________________________
activation_279 (Activation)     (None, 13, 13, 384)  0           batch_normalization_189[0][0]
__________________________________________________________________________________________________
activation_283 (Activation)     (None, 13, 13, 384)  0           batch_normalization_193[0][0]
__________________________________________________________________________________________________
conv2d_190 (Conv2D)             (None, 13, 13, 384)  442368      activation_279[0][0]
__________________________________________________________________________________________________
conv2d_191 (Conv2D)             (None, 13, 13, 384)  442368      activation_279[0][0]
__________________________________________________________________________________________________
conv2d_194 (Conv2D)             (None, 13, 13, 384)  442368      activation_283[0][0]
__________________________________________________________________________________________________
conv2d_195 (Conv2D)             (None, 13, 13, 384)  442368      activation_283[0][0]
__________________________________________________________________________________________________
average_pooling2d_18 (AveragePo (None, 13, 13, 2048) 0           mixed9[0][0]
__________________________________________________________________________________________________
conv2d_188 (Conv2D)             (None, 13, 13, 320)  655360      mixed9[0][0]
__________________________________________________________________________________________________
batch_normalization_190 (BatchN (None, 13, 13, 384)  1152        conv2d_190[0][0]
__________________________________________________________________________________________________
batch_normalization_191 (BatchN (None, 13, 13, 384)  1152        conv2d_191[0][0]
__________________________________________________________________________________________________
batch_normalization_194 (BatchN (None, 13, 13, 384)  1152        conv2d_194[0][0]
__________________________________________________________________________________________________
batch_normalization_195 (BatchN (None, 13, 13, 384)  1152        conv2d_195[0][0]
__________________________________________________________________________________________________
conv2d_196 (Conv2D)             (None, 13, 13, 192)  393216      average_pooling2d_18[0][0]
__________________________________________________________________________________________________
batch_normalization_188 (BatchN (None, 13, 13, 320)  960         conv2d_188[0][0]
__________________________________________________________________________________________________
activation_280 (Activation)     (None, 13, 13, 384)  0           batch_normalization_190[0][0]
__________________________________________________________________________________________________
activation_281 (Activation)     (None, 13, 13, 384)  0           batch_normalization_191[0][0]
__________________________________________________________________________________________________
activation_284 (Activation)     (None, 13, 13, 384)  0           batch_normalization_194[0][0]
__________________________________________________________________________________________________
activation_285 (Activation)     (None, 13, 13, 384)  0           batch_normalization_195[0][0]
__________________________________________________________________________________________________
batch_normalization_196 (BatchN (None, 13, 13, 192)  576         conv2d_196[0][0]
__________________________________________________________________________________________________
activation_278 (Activation)     (None, 13, 13, 320)  0           batch_normalization_188[0][0]
__________________________________________________________________________________________________
mixed9_1 (Concatenate)          (None, 13, 13, 768)  0           activation_280[0][0]
                                                                 activation_281[0][0]
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 13, 13, 768)  0           activation_284[0][0]
                                                                 activation_285[0][0]
__________________________________________________________________________________________________
activation_286 (Activation)     (None, 13, 13, 192)  0           batch_normalization_196[0][0]
__________________________________________________________________________________________________
mixed10 (Concatenate)           (None, 13, 13, 2048) 0           activation_278[0][0]
                                                                 mixed9_1[0][0]
                                                                 concatenate_4[0][0]
                                                                 activation_286[0][0]
__________________________________________________________________________________________________
global_average_pooling2d_6 (Glo (None, 2048)         0           mixed10[0][0]
==================================================================================================
Total params: 21,802,784
Trainable params: 21,768,352
Non-trainable params: 34,432
__________________________________________________________________________________________________
257/257 [==============================] - 261s 1s/step
73/73 [==============================] - 72s 991ms/step
X_train shape: (16448, 6144)
X_valid shape: (4672, 6144)
y_train shape: (16448,)
y_valid shape: (4672,)
X_train[0]: [0.4348169  0.38198537 0.4465128  ... 0.04982465 0.01868366 0.03262734]
X_valid[0]: [1.8912454e-01 7.6481187e-01 7.9932952e-01 ... 2.3976736e-02 7.0650596e-04
 5.4836543e-03]
y_train[0]: 0
y_valid[0]: 0
X_train shape:  (16448, 6144)
y_train shape:  (16448, 10)
X_valid shape:  (4672, 6144)
y_valid shape:  (4672, 10)
Train on 16448 samples, validate on 4672 samples
Epoch 1/60
16448/16448 [==============================] - 25s 2ms/step - loss: 1.4559 - acc: 0.5671 - val_loss: 0.9322 - val_acc: 0.7536

Epoch 00001: val_loss improved from inf to 0.93222, saving model to ./model/weights.best.merge.hdf5
Epoch 2/60
16448/16448 [==============================] - 5s 292us/step - loss: 0.4674 - acc: 0.8700 - val_loss: 0.7097 - val_acc: 0.7894

Epoch 00002: val_loss improved from 0.93222 to 0.70972, saving model to ./model/weights.best.merge.hdf5
Epoch 3/60
16448/16448 [==============================] - 5s 285us/step - loss: 0.2855 - acc: 0.9232 - val_loss: 0.7018 - val_acc: 0.7778

Epoch 00003: val_loss improved from 0.70972 to 0.70178, saving model to ./model/weights.best.merge.hdf5
Epoch 4/60
16448/16448 [==============================] - 5s 288us/step - loss: 0.2226 - acc: 0.9399 - val_loss: 0.7031 - val_acc: 0.7487

Epoch 00004: val_loss did not improve from 0.70178
Epoch 5/60
16448/16448 [==============================] - 5s 286us/step - loss: 0.1574 - acc: 0.9573 - val_loss: 0.6034 - val_acc: 0.7958

Epoch 00005: val_loss improved from 0.70178 to 0.60340, saving model to ./model/weights.best.merge.hdf5
Epoch 6/60
16448/16448 [==============================] - 5s 283us/step - loss: 0.1657 - acc: 0.9531 - val_loss: 0.6267 - val_acc: 0.7770

Epoch 00006: val_loss did not improve from 0.60340
Epoch 7/60
16448/16448 [==============================] - 5s 283us/step - loss: 0.1653 - acc: 0.9522 - val_loss: 0.7761 - val_acc: 0.7301

Epoch 00007: val_loss did not improve from 0.60340
Epoch 8/60
16448/16448 [==============================] - 5s 289us/step - loss: 0.1513 - acc: 0.9557 - val_loss: 0.6363 - val_acc: 0.7815

Epoch 00008: val_loss did not improve from 0.60340
Epoch 9/60
16448/16448 [==============================] - 5s 282us/step - loss: 0.1604 - acc: 0.9499 - val_loss: 0.5282 - val_acc: 0.8112

Epoch 00009: val_loss improved from 0.60340 to 0.52815, saving model to ./model/weights.best.merge.hdf5
Epoch 10/60
16448/16448 [==============================] - 5s 286us/step - loss: 0.1630 - acc: 0.9474 - val_loss: 0.4053 - val_acc: 0.8682

Epoch 00010: val_loss improved from 0.52815 to 0.40534, saving model to ./model/weights.best.merge.hdf5
Epoch 11/60
16448/16448 [==============================] - 5s 280us/step - loss: 0.2084 - acc: 0.9305 - val_loss: 0.6922 - val_acc: 0.7648

Epoch 00011: val_loss did not improve from 0.40534
Epoch 12/60
16448/16448 [==============================] - 5s 291us/step - loss: 0.2204 - acc: 0.9233 - val_loss: 0.4672 - val_acc: 0.8502

Epoch 00012: val_loss did not improve from 0.40534
Epoch 13/60
16448/16448 [==============================] - 5s 287us/step - loss: 0.1938 - acc: 0.9297 - val_loss: 0.6704 - val_acc: 0.7744

Epoch 00013: val_loss did not improve from 0.40534
Epoch 14/60
16448/16448 [==============================] - 5s 282us/step - loss: 0.1845 - acc: 0.9342 - val_loss: 0.5788 - val_acc: 0.8129

Epoch 00014: val_loss did not improve from 0.40534
Epoch 15/60
16448/16448 [==============================] - 5s 294us/step - loss: 0.1731 - acc: 0.9386 - val_loss: 0.5217 - val_acc: 0.8303

Epoch 00015: val_loss did not improve from 0.40534
Epoch 16/60
16448/16448 [==============================] - 5s 291us/step - loss: 0.1556 - acc: 0.9439 - val_loss: 0.5712 - val_acc: 0.8061

Epoch 00016: val_loss did not improve from 0.40534
Epoch 17/60
16448/16448 [==============================] - 5s 285us/step - loss: 0.1648 - acc: 0.9405 - val_loss: 0.5918 - val_acc: 0.8196

Epoch 00017: val_loss did not improve from 0.40534
Epoch 18/60
16448/16448 [==============================] - 5s 277us/step - loss: 0.1617 - acc: 0.9413 - val_loss: 0.7131 - val_acc: 0.7744

Epoch 00018: val_loss did not improve from 0.40534
Epoch 19/60
16448/16448 [==============================] - 5s 285us/step - loss: 0.1616 - acc: 0.9388 - val_loss: 0.8177 - val_acc: 0.7481

Epoch 00019: val_loss did not improve from 0.40534
Epoch 20/60
16448/16448 [==============================] - 5s 286us/step - loss: 0.2113 - acc: 0.9210 - val_loss: 0.5710 - val_acc: 0.8108

Epoch 00020: val_loss did not improve from 0.40534
